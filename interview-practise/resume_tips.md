## REVIEW OF RESUME（阿菜2019年自制面经）

[某个大佬的面试心得](https://aleiwu.com/post/interview-experience/)

------------------
### 1. 换位思考
    我的简历上描述最多的就是爬虫的部分了，因为爬虫系统其实才是这个系统的核心，事实上我想找的更加偏向于后端业务逻辑系统的开发，所以我才放了后面的两个项目。但是面试官第一眼看到的就是爬虫的东西，所以一开始上来就问爬虫。
    
    到现在为止我一共经历了三场面试，三场面试无一例外都是更多的问一些和爬虫相关的东西多一些，然后是python的基础知识的掌握程度、对Django框架的了解、一些基础的后端编程知识。还有的问题就是，数据库各个表之间的关系，高并发的实现，爬虫的连接部分。
    
    ====2019-07-21====
    杭州的那家面完了。其实工作一年，公司真的不指望你会多少东西，所以基本上问的都是一些非常基础的东西。如果基础比较好的话，就算是对redis、celery、kafka这些东西掌握地不好，也不会太过于苛求。公司更在在乎你是不是稳定，有没有自我学习的能力，公司可不会希望招了你以后，培养好过了试用期，然后你就跳槽了。当然也可能有我是女生的缘故吧。但是这次让我更加坚信一点，我现在打的是一场只要准备，就可以打地很好的仗。

------------------
### 2. 我的想法
    首先我是一个应届毕业生，面试官问我的肯定都是一些基础的知识。我已经有一个在应届生里面比较能拿的出手的项目经验了，其实我只要把项目中遇到的难点以及基础知识解决了，我觉得就没有问题了。

------------------
### 3. 先自我介绍一下吧
    姓名，应届，工作经历，目前所负责过的项目。之前面试的时候我都是说到猫头鹰的时候就开始深入往下介绍了，由于猫头鹰的核心其实是爬虫系统，所以我这一次决定改变一下介绍的方式，我要把我简历上做过的三个项目全都说一遍，再开始进行项目介绍。

------------------
### 4. 你遇到过哪几种反爬的网站机制

#### 4.1. 通过设置request里的headers里的User-Agent来限制访问，有的网站会限制User-Agent访问白名单，只有在正常范围内的User-Agent，才能访问这个网站。

#### 4.2. 通过设置request里的headers里的Cookies来限制访问。
    1. 有的网站第一次访问的时候，返回的html里面内嵌这一js代码，这段js的代码的功能就是会生成一端随机的字符串，然后重新访问原网址，第二次访问是携带动态生成的cookies的，才能访问成功。比如银保监。
    
    2. 有的网站第一次访问的时候，会在返回的response的headers里面返回一个cookie1。然后在response的body里面某个标签里面隐藏一个cookie2, 接下来的访问需要携带这两个cookies才能返回正确的请求体。比如github.
    
    3. 有的网站需要登陆以后才能访问其它页面，模拟登录成功以后才能拿到cookies,携带这些cookies访问才能得到正确的相应体。厉害一点的网站，会在登录的时候发送的POST请求体中的用户名和密码加上密，这样我们在模拟登陆的时候就要花费点功夫了。
    
    4. 其实通过cookies限制访问的破解方法都是大同小异的，找到请求的顺序，能读懂js脚本，就可以解决大部分的反扒网站。但是想中央人民银行这样的，连js脚本都是加密过的，就很难做了。

#### 4.3. 通过ban掉频繁访问的ip来限制访问
    1. 比如微信搜狗，访问频繁以后就出现数字验证码。
    2. 比如深交所，访问频繁了以后就会限制访问，但是过一段时间就会恢复ip访问。
    3. 这种情况优先考虑建立和维护自己的ip代理池进行访问。

##### (这里埋下了一个坑，面试官一定会问ip代理池是怎么做的)

#### 4.4. 验证码来限制访问
    1. 比如京东，比如微信搜狗，比如bilibili，比如12306
    2. 借助第三方的打码平台

------------------
### 5. 说一下你的ip代理池是怎么维护的
    1. 所有的IP代理来源是西刺免费代理，所有的爬取到的代理都放在Redis中。每个IP在刚抓取到的时候都会给到100分的初始分数。
    
    2. 会有一个Schedule定时去检查Redis中代理的可用性。刚爬取到的IP代理都存在redis的一个List1中。每个检测失败的IP都扣5分，如果还有剩余的分数，就存回到List1中。如果失败了，就从List中删除。如果检验通过了就存入另一个新的List2中。
    
    3. 其实还可以实现一个或者多个代理接口。
    ====================
    题外话：
    王叔曾经提出一个方法，使用阿里云上面的虚拟手机，然后让android的同学写一个程序，每个手机都有一个自己的IP，把这台手机变成一个代理。其实我觉得蛮好的，反正后来也不知道什么原因就没有这样实现了。

------------------
### 6. 说一下是怎么使用celery把任务扔给爬虫的。
    1. 首先会有一个脚本每隔5s去MySQL将所有的源都取出来，然后进行分流。先分成普通的源和需要动态渲染的源，然后按照间隔时间进行分流，可以分成六个包，存在redis的list中。
    
    2. 会有三个进程，分别是每15s,每30s,每60s，15s_process会去key为15s_normal的redis的list，和，key为15s_render的redis的list中拿出任务源，然后扔进一个key为normal_jobs的redis的list当中去。其它几个都类似。
    
    3. 此时还有两个脚本，分别从normal_jobs中每15个一取，转换成为一个json字符串，然后存进redis中。然后执行task_name.delay(key)启动相关的爬虫，然后爬虫就可以通过redis的key拿到对应的任务源列表。并且执行了。
    
    题外话again,所以任务堆积一定是堆积在这个地方了，找个机会还原一下看看。

-------------------
### 7. 你为什么要在转正以后才跳槽（你为什么离开上一家公司）
    如果我是面试官，我问出这个问题，那么我心里想的一定是，如果我把你招进来了，我在你试用期的时候把你培养好了，但是你以转正就走了，我就白培养了。同样，你在这家公司如果工作不满一年，就意味着你这个人不稳定。
##### 我的回答：
    1. 我目前所负责的项目已经完成了主要的开发，剩下的都是一些维护的工作。由于我目前所在的小组单独分出来，只负责猫头鹰部分，目前的给到我的已经没有什么能提升到我的能力的工作了。
    2. 在今年的四月份，我们小组一共三个人，其它两个同事因为个人的原因选择了其他的公司，所以目前这个项目我是主要的开发人员和维护人员。我没有多余的精力和时间去做提升自己的事情。
    3. 现在我们小组的其他两个人员目前都已经熟悉了开发流程和运维流程，所以我选择这个时候出来找工作，希望能有一份挑战自己的工作机会。

-------------------
### 8. 你平时周末都会干些什么事情（你平时是怎么学习的?）
    这个问题，我只能说，自古深情留不住，唯有套路得人心。面试中你的每一个回答，都是在给自己埋坑。不要瞎jb编。
#### 8.1 如果你说，我平时的学习方式是看书。面试官接下来就会问：
    1. 你都看过哪些书呢？
    2. 能说一点你在看书中最让你恍然大悟的知识点是什么吗？
#### 8.3 如果你说，我平时的学习方式是刷github。面试官接下来就会问：
    1. 有什么开源项目是你看过比较好的呢？

------------------
### 9. 同样的，因为我的简历上面，爬虫的篇幅大于后端，但是我找的都是后端开发的工作，所以面试官会问，你既然想做后端，那么你平时有针对后端方面的开发学习做出过什么努力吗？
    这里我的回答真的超级垃圾，因为我github上面的基本上全都是和爬虫相关的，后端的我真的没看，要是瞎掰的话，被问出来，给人的印象就会更加糟糕，所以我就直接说我平时没怎么做过后端相关方面的学习，这个回答真的糟糕透顶，今后的回答中一定要规避掉这点。所以后端方面相关的知识点我要好好再复习一道。

------------------
### 10. 你这个项目一共多少个人做，做了多长时间
    因人而异，所以不写了。

------------------
### 11. 你们每个人在这个项目当中承担的主要角色是什么
    因人而异，所以不写了。