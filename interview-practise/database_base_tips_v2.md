## Redis 篇

### 1. Redis 常见的数据结构以及使用场景

**基础回答:**

+ string - `使用场景：缓存、计数、共享 Session、限频`

+ hash - `应用场景：限频`。

+ list 双向链表 - `应用场景：简单的消息队列的功能`

+ set - `不重复、无序 应用场景:计算共同喜好，全部的喜好，自己独有的喜好`

+ sorted set - `多了一个权重参数 score, 集合中的元素能够按照 score 进行排列, 这个是在插入时就排序好的。应用场景：排行榜应用，比如热搜榜。`

**中高阶回答:**

+ HyperLogLog
+ Geo
+ Pub/Sub

**加分回答：**

+ BloomFilter
+ RedisSearch
+ RedisML

### 2. Redis 持久化的几种方式

Redis 的 **持久化策略** 有两种：

+ **RDB（Redis 默认持久化策略）**
  
  在指定的时间间隔内将内存中的数据集快照写入磁盘，实际过程是 fork 一个子进程，子进程将数据写到磁盘上的一个临时 RDB 文件中，写入成功后，以二进制压缩存储，一个 dump.rdb 文件。这样做的 **好处** 就是可以 **copy-on-write**。当然也可以手动执行 save 或 bgsave 做快照。
  
  + **优势**
    1. 在发生灾难时轻松 **还原** 数据集的 **不同版本**。
    2. RDB 文件是一个 **紧凑** 的文件，二进制存储嘛，可以进行远程传输。
    3. RDB 最大限度地提高了 Redis 的 **性能**，因为 父进程 的唯一工作就是分派 一个孩子进程，孩子进程会完成剩下工作。父进程不会执行 I/O 操作。
    4. 与 AOF 相比，RDB 允许大型数据集服务器**更快地重启(AOF在重启之前要重新执行一遍 AOF 日志文件，所以说更快)**。
  + **缺点**
    1. 即使每 5min 创建一次 RDB 快照，Redis 出现故障停止工作，还是会 **丢失几分钟的数据**。
    2. **RDB 经常使用 fork**，如果数据集很大，fork 可能很耗时，万一数据集很大，CPU 性能不佳，则可能导致 Redis 停止为客户端服务几毫秒甚至一秒。**AOF 也需要 fork 进程，但是可以调整重写日志的频率**

+ **AOF** 
  
  记录服务器接收的每个写入操作，这些操作将在服务器启动时进行重放，以重建原始数据集。仅采用追加的方式，当日志太大时，Redis 可以在后台重写日志。每一个写命令都通过 write 函数追加到 appendonly.aof 中。appendonly.aof 以文本的方式记录。
  
  + **优势**
    1. **最多只丢失 一秒钟 的数据**。AOF的默认策略是每秒钟 fsync 一次。且 fsync 的性能良好。fsync 会在后台线程执行，所以主线程可以努力地处理命令请求。
    2. AOF 日志是仅追加的日志，**如果断电，不会出现寻道或者损坏的问题**。（？？没明白）
    3. Redis 会在后台自动重写 AOF，**重写是完全安全的**，追加时会生成一个全新的文件，其中包含创建当前数据集所需要的最少操作集，一旦准备好第二个文件，Redis 会切换这两个文件并开始追加到新的那一个。
    4. **AOF 以易于理解和解析的格式书写操作日志**。可以轻松导出 AOF 文件，修改 AOF 文件(删除命令等等)，然后重新启动 Redis 即可。
  + **缺点**
    1. 对于相同的数据集来说，AOF 的文件体积通常 **要大** 于 RDB 文件的体积。
    2. 根据所使用的 fsync 策略，AOF 策略可能 **会慢** 于 RDB。关闭 fsync 可以让两者的速度一样快，即使在高负荷之下也是如此。

+ **总结**
  
  因此如果可以在发生灾难时承受几分钟的数据丢失，则可以使用 RDB。另外 **不建议单独使用 AOF**，因为它会将每一条命令都追加到磁盘中，处理巨大的写入会 **降低** Redis 的 **性能** 。因此我觉得定时生成 RDB 快照(比如 每5min 生成一次快照)，同时开启 RDB 和 AOF(比如每 5min 重写一次)，这样系统重启以后会优先使用 AOF 来恢复数据，这样丢失的数据最少。对于主从同步来说，主从刚刚连接时，进行全量同步，全量同步结束以后，进行增量同步。

### 3. 持久化发生了什么？

```markdown
1. client 像 server 端发送写命令，此时数据在客户端的内存中
2. server 端接收到写请求以后，此时数据在服务器的内存中
3. server 调用系统 API 将数据写入磁盘，此时数据在内核缓冲区中
4. 操作系统将写缓冲区传输到磁盘控制器，此时数据在磁盘写缓存中
5. 操作系统的磁盘控制器将数据写入实际的物理媒介中，此时数据在磁盘中
```

```markdown
加分点：
从第三步开始，Linux 提供了用于操作文件的 POSIX file API，有 open、close、write、reload。在磁盘写缓冲区中的数据并不会马上被写入磁盘，默认情况下，Linux 将在 30s 之后实际提交写入。显然 Redis 是不能接受 30s 的。POSIX API 提供了另外一个解决方案，fsync。该命令会强制内核将缓冲区的数据写入磁盘，是一个十分消耗性能的操作。每次调用都会阻塞等待直到设备报告 IO 完成。所以一般生产环境中，Redis 通常是1s执行一次。
```

### 3. RDB save  && bgsave

```shell
使用：
# 至少更改了 1000 个键，则每 60s 自动将数据集转储到磁盘上       
save 60 1000
bgsave (?)

区别：
save 执行一个同步保存操作，会阻塞所有的客户端
bgsave 则是 fork 出一个后台进程进行保存，父进程仍能处理客户端请求

bgsave 过程：
1. redis fork 出一个子进程
2. 子进程开始将数据集写入临时的 RDB 文件
3. 完成新的 RDB 文件写入后，替换旧的 RDB 文件
```

### 7. 怎么在 bgsave 开始到结束能保证新的命令导致的数据变化也能保存到数据库中？

```markdown
1. redis 创建子进程后，不会进行数据的 copy，主进程和子进程是共享数据的，主进程则继续对外提供读写服务
2. kernel 会把主进程中的所有内存页权限设置为 read-only，然后父子进程访问数据的指针指向统一内存地址
3. 主进程发生写操作时，由于权限已经设置为 read-only 了，所以会触发页异常中断。在中断处理中，需要被写入的内存页面会复制一份，复制出来的旧数据给子进程用，主进程该干啥干啥。

Q：bgsave 持久化的是某一个时间点的数据。那么如果要做到在 bgsave 的期间也能把发生的操作放进 rdb 里该怎么办呢？
A1：面试官想问的是混合持久化？
A2：先问面试官是单机还是分布式？如果是分布式的话，就涉及到 主从 backlog？
```

### 8. Redis 的混合持久化方式

```json
redis 4.0 之后提供了混合持久化的方式。混合持久化只发生于 AOF 重写过程。使用了混合持久化，重写后的新 AOF 文件前半段是 RDB 格式的全量数据，后半段是 AOF 格式的增量数据。redis 5.0 中混合持久化的开关默认打开。

1. fork 子进程，将当前全量数据以 RDB 方式写入新的 AOF 文件
2. 将 AOF 重写缓冲区的增量命令以 AOF 的方式写入文件
3. 写入完成后通知主进程将新的含有 RDB 格式 和 AOF 格式的 AOF 文件替换旧文件
```

### 4. AOF appendonly

```shell
# 从现在开始，每次 redis 收到更改数据集的命令，都将添加到 AOF
appendonly yes

# 可以配置 fsync 模式
appendfsync always: 将每条命令都附加进 aof，会很慢
appendfsync everysec: 每秒 fsync 一次，速度足够快，最多丢失 1s 的数据
appendfsync no：从不 fsync, 只需要将数据交给操作系统即可，更快，更不安全，Linux 使用此配置每 30s 刷新一次数据，取决于内核的精确调整。

过程：
1. redis fork 一个子进程
2. 子进程开始在临时文件中写入新的 aof
3. 父进程将所有新的更改累积在内存缓冲区中，同时会将新的更改写入旧的 aof 文件中
4. 子进程完成文件重写以后，父进程会收到信号，在子进程生成的 aof 文件末尾附加内容
5. redis 将旧文件命名为新文件，现在新命令将追加到新文件中
```

```markdown
问题：
如果要增加一个计数器 100 次，最终在数据集的数据键只有一个，AOF 却包含 100 项。

解决：
redis 支持在后台重建 AOF，而不会中断对客户端的服务。每当您发出 bgrewriteaof 时，redis 都会编写最短的命令序列来重建内存中的数据集。并且 redis 2.4 能够自动触发日志重写。
```

### 5.  如果 AOF 中的最后一条命令被截断该怎么办？

```markdown
Redis 的最新版本仍能加载 AOF, 只需丢弃文件中最后一个格式不正确的命令即可。也可以配置，无论文件最后一个命令是否正确，默认配置都是继续执行，以确保重新启动后的可用性。

Redis 的旧版本可能无法恢复，并且需要执行如下步骤：
1. 制作 AOF 的副本
2. 使用 redis-check-aof 随附工具来修复原始文件
3. 用固定文件重新启动服务器
```

### 6. 如果 AOF 文件遭到损坏怎么办？

```markdown
Redis 会在启动的时候就报错中止。最好的方式是运行 redis-check-aof。首先不带 --fix 选项，然后跳转到文件中的给定偏移，尝试手动修复。或者可以让 redis-check-aof 为我们修复，但是可能就是把无效的部分都丢弃了，会造成大量数据损失。
```

### 9. Redis 的 LRU(Last Recent Used) 具体实现(这个答案保持疑问，文档似乎不是这样写的)

据说是以前头条的面试题

#### Last Recent Used 是什么？

因为计算机的缓存容量有限，缓存满了就需要删除一些内容，给新的腾位置。LRU 就一种常用的页面置换算法，选择最近最久未使用的页面予以淘汰。

#### 自己实现 LRU 算法

数据结构的选法很重要，要求查找快(查找放入插入键之前是否存在)，插入快(如果不存在的话就插入队头)，删除快(容量满了删除队尾数据)，且有顺序，因为有最近使用和久未使用的顺序之分。如果插入键存在，则还可能要将队中的数据挪到队头。

**hash 表**：查找快，但是数据无固定顺序

**链表**：插入、删除都快，但是查找慢

因此就有了一种新的数据结构，**哈希链表**。

因此 hash 表里 key 存储节点的 值，value 存储 指向节点的指针，就可以实现以上目的了。链表的话可以使用双向链表，或者单链表吧。**要注意的是**，在处理链表节点的同时，不要忘记更新哈希表中对节点的映射。

#### Redis 的实现

Redis 作为缓存使用时，要考虑内存空间消耗的问题。Redis 会删除过期键释放空间(有惰性删除、定期删除)。另外 Redis 也可以开启 LRU 功能来自动淘汰一些键值对。

**初始版本中**：Redis 每次按照 key 获取一个值时，都会更新 value 中的 LRU 字段为当前秒级别的时间戳。因此随机从 Dict 中取出 5 个 key，淘汰一个 LRU 字段值最小的。

**3.0版本中**：首先第一次随机选取的 key 都会放进 pool 中(pool 的大小为 16)，接下来每次随机选取的 key 的 LRU 值 **必须小于** pool 中最小的才会继续放入，pool 中的 key 是按照 LRU 大小顺序排列的，直至将 pool 放满。再之后，如果有新的 key 需要放入，需要将 pool 中最大的 key 取出，放入。淘汰的时候，直接取出 pool 中最小的 LRU 的 key 进行删除。

**4.0版本中**：引入新的 LFU(最不常用) 驱逐策略。LFU 尝试跟踪物品的访问频率，因此，很少使用的数据会被驱逐，经常使用的数据则有较高的机会保留在内存中。

### 10. 单线程的 Redis 为什么快？

CPU 并不是您使用 Redis 的瓶颈，因为 Redis 是和 **内存** 与 **网络** 绑定的。例如，一般 Redis 每秒可以发送 100W 个请求。因此，如果您的应用程序主要使用 O(N) 或 O(logN) 命令，则几乎不会过多使用 CPU。使用多线程带来的性能成本并不能抵消它带来的开发成本和维护成本，系统的性能瓶颈也主要在网络 IO 操作上。并且这里的单线程指的是 处理客户端的命令，前文介绍的 RDB 和 AOF 都是 fork 出子进程去做的。

+ **完全基于内存**

+ **采用单线程，避免了不必要的上下文切换和竞争条件，不用考虑各种锁的问题(加锁、释放锁)，没有因为可能出现死锁而导致的性能消耗。**

+ **采用 IO 多路复用模型**

+ **高效的数据结构，底层做了大量的优化，比如不同长度的字符串使用不同的结构体表示**

#### 4.1 进程线程是什么，区别是什么，各自的优缺点是什么？

#### 4.2 什么是 多路 I/O 复用模型？Redis 的 多路复用应用？

**多路**：多个客户端连接(连接就是套接字描述符 FD)

**复用**：使用单进程能够实现同时处理多个客户端的连接

在当代 Unix 操作系统中提供了 **`select`**、**`poll`**、**`epoll`** 这样的 system call，这些 system call 的功能就是：你告诉我一批 socket，当这些套接字的 可读/可写 事件发生时，我会通知你这些信息。多路 IO 复用模块相当于 socket 和 处理者 之间传话的一个中介。这样 CPU 就可以实现对 **多个** FD 的 **同时读写** 了。

**Redis 里采用了 Reactor 设计模式**

(多个 socket) -> 多路IO复用程序 -> 文件事件分派器 -> 各自的文件事件处理器。(比如：命令请求处理器、命令回复处理器、连接应答处理器)。

这里可以减少网络 IO 的时间消耗，避免无用操作，但是文件事件的处理，依旧还是顺序处理的。

**一点很杂的知识：**

`select` 函数是作为 POSIX 标准中的系统调用，在不同版本的操作系统上都会实现，因此，在 Solaries10 上，Redis 会用 `enport`，在 Linux 上用 `epoll`，在 OSX 和 FreeBSD 上使用 `kqueue` 和 `select`(备选机制)。前三个的时间复杂度都是 O(1)，`select` 是轮询机制，所以是 O(N)。 

### 11. Redis 的数据过期策略

+ **定期删除策略**
  
  Redis 启用一个定时器定时监视所有的 key，判断 key 是否过期，过期的话就删除。
  
  **优点**：这种策略可以保证过期的 key 最终都会被删除。**缺点**：每次都要遍历内存中的所有数据，**非常消耗** CPU 资源，并且当 key 已经过期，但是定时器还处于未唤起状态，这段时间内的 key 也仍然是可用的。

+ **惰性删除策略**
  
  在获取 key 时，先判断 key 是否过期，如果过期则删除。
  
  **优点**：不用每次都遍历内存中的策略了，而且可以保证超过过期时间以后肯定获取不到。**缺点**：如果这个 key 一直未被获取，则会一直存在于内存中，浪费空间。

+ **结合使用**
  
  定时删除策略随机抽取一部分的 key 进行检查，降低 CPU 的消耗。惰性删除则不变。
  
  **所以有的数据既没有被定时器抽取到，也没有被使用到，那么这些数据如何从内存中消失呢？**

#### 内存淘汰机制(当内存不足以容纳新写入的数据时)：

+ 新写入操作就会报错。（Redis **默认策略**）
+ 在键空间中，移除最近最少使用的 key。(LRU)
+ 在设置了过期时间的键空间中，移除最近最少使用的 key。这种情况一般把 Redis 当作缓存，但是又需要做持久化存储的时候使用。(why??)

### 12. 如何解决 Redis 缓存雪崩的问题？

```markdown
缓存雪崩是指某一时刻发生大规模的缓存失效的情况，比如 缓存服务器宕机了。这时就会有大量的请求直接打到 DB 上，DB 撑不住，就挂掉了。

1. 雪崩前 - 使用 Redis 主从架构 或者 集群 缓存，保证缓存服务高可用。
2. 雪崩前 - 我们在设置缓存的时候，一般会给缓存设一个失效时间。那么对于一些热点数据来说，如果设置一样的缓存失效时间就可能会发生缓存雪崩，因此解决方案就是 设置不同的缓存失效的时间，比如说加上一个随机值。
3. 雪崩中 - 限流降级策略。限流就是提高各个类型的请求设置最高的 QPS 值，如果高于阈值之后的请求直接返回，不再调用后续的资源。降级就是当服务器压力剧增的情况下，根据当前业务情况及流量对一些服务和页面有策略的降级，从此释放服务器资源以保证核心任务的正常运行。
4. 雪崩后 - redis 持久化，重新启动以后自动从磁盘加载数据，快速恢复缓存数据。
```

### 13. 如何解决 Redis 缓存穿透的问题？

```markdown
缓存击穿是指当大量请求去请求缓存中不存在的 key 时，这是请求就会集中到 DB 上，导致 DB 压力剧增。

1. 在查询缓存之前，采用布隆过滤器，将所有可能存在的数据 哈希 到一个很大的 bitmap 中去。如果查询的数据在布隆过滤器中不存在，则不查询缓存。
2. 将不存在的 key 存进 Redis，`set key null`，过期时间设的很短，不超过 5 分钟。
```

### 14. Redis 并发竞争 key 如何解决

就是说当有多个 redis-client 同时 set 用一个 key 时。

+ 在分布式环境，加 **分布式锁**。用一个状态值表示锁，对锁的占用和释放都通过状态值进行标识。适用于 **无顺序需求** 的场景。
+ 利用 **时间戳** 和 **消息队列**。适用于 **有序需求** 的场景。

### 15. Redis 的主从模式、哨兵模式、集群(cluster)模式 之间的区别

#### 15.1 主从模式：

通过 `slaveof` 命令让一个服务器去复制另一个服务器的数据。被复制的服务器成为：**master 主服务**。对主服务器进行复制的服务器成为：**slave 从服务器**。主数据库可以进行读写操作，当写操作导致数据发生变化时，**自动(?)** 将数据同步给从数据库。从数据库一般是只读的。主从数据库是一对多的关系。主从模式是在单机上的。

**通信过程(异步复制)**：

1. 从服务器 向 主服务器 发送 SYNC 命令
2. 主服务器收到命令后，执行 BGSAVE 命令，在后台生成 RDB 文件。收集缓冲区记录里，从现在开始执行的所有操作记录。
3. 主服务器 BGSAVE 执行结束后，主服务器将 RDB 文件 和 操作记录 发给从服务器。
4. 从服务器一边执行指令流来达到和主节点一致的状态，一边像主节点反馈同步情况。

**主从模式的问题：当 master 挂了，需要在 slave 中选举一台成为 master，要实现自动，就需要 redis 哨兵。**

#### 15.2 哨兵模式(Sentinel)

哨兵模式核心仍是主从模式，但是多了竞选机制，可以从挂了的 **主节点的从节点中** 竞选出新的主节点。竞选机制的实现，依赖于 Sentinel 进程。

**Sentinel 特点**：

+ **监控**：坚听 主服务器 和 从服务器 之间是否正常工作
+ **通知**：能通过 API 告诉系统管理员或程序，集群中的某个实例出现了问题
+ **故障转移**：它在主节点出问题的情况下，会从出问题的主节点下的从节点中竞选出一个节点成为新的主节点
+ **提供主服务器地址**：它还能够向使用者提供当前主节点的地址。故障转移后，使用者不用做任何修改就可以知道当前主节点地址。

Sentinel，也可以集群，也可以部署多个。Sentinel 可以通过发布订阅自动发现集群中的其它 Sentinel。所有的 Sentinel 都会存储在一个列表中，**因此集群中的 Sentinel 不会并发着去对同一个节点进行故障转移。**故障转移只会从第一个 Sentinel 开始，当第一个转移失败后，才会尝试下一个。

当竞选出新的主节点后，被选为新的主节点的从节点的配置信息会被 Sentinel 改写为旧的主节点的配置信息。完成改写后，再将新主节点的配置广播给所有的从节点。

#### 15.3 集群模式

1. **集群** 是 Redis 提供的分布式数据库方案，通过分片进行数据共享， 分片是为了解决数据量过大在单个节点上造成巨大压力的问题，它能带来：
   
   a. 自动对数据分片，落到各个节点上。
   
   b. 当一部分节点出现故障或无法与其余集群通信时，仍然可以继续工作

2. 每个 Redis 集群里的节点，都需要打开 **两个 TCP 端口**，否则集群无法正常工作。
   
   a. 普通的 **命令端口** 如 6379，用于服务客户端。
   
   b. 在普通端口加1000，如 16379，称为 **集群总线端口**，用于故障检测、配置更新、故障转移授权等等。客户端永远不要尝试与集群总线端口通信。

3. 集群节点之间采用 **gossip 协议** 进行通信，所有的节点都持有一份元数据，不同的节点出现了元数据的变化就不断将元数据发送给其它的节点，让其它节点也进行元数据的变更。好处是，打到所有节点上去更新，降低了压力。缺点是，可能导致集群中的一些消息滞后。

4. 另外 gossip 协议的特点就是，在节点数量有限的网络中，每个节点都 “随机” 与 部分节点通信，经过一番杂乱无章的通信，每个节点的状态很快会达到一致。gossip 协议的有点有负载低，去中心化，容错性高。缺点是集群的收敛速度慢。

（命令端口 和 集群总线端口 的偏移是固定的，始终是 1000）

#### 15.4 集群一致性保证

Redis Cluster 无法保证 **强一致性**。在某些情况下，可能丢失系统认可给客户端的写入。

**第一个原因：使用异步复制。**

+ client 在 主B 执行写操作
+ 主B 向 client 答复"确定"
+ 主B 将写操作传播到 从B1、从B2、从B3

B在回复客户端之前 **不会等待** B1、B2、B3 的 **确认**，因为这会对 Redis 造成极高的延迟影响。这时如果这个 主B 挂了，写操作还没同步过去，从B 竞选为 主B，这样就会永远丢失写操作。

**解决方案：**

当然可以强制在 主B 回复 客户端之前，同步给 从B 们。这是性能和一致性之间的权衡。

但即使使用 **同步复制**，Redis Cluster 也 **无法实现** 强一致性。因为在更复杂的故障情况下，总是有可能将无法接受写入的从设备选为主设备。

**第二个原因：Redis Cluster 可能丢失写数据，这种情况发生在网络分区期间，在该分区中，客户端与少数实例隔离**

假如我们的集群有 6 个节点，三主三从(A，B，C，A1，B1，C1)。有一个客户 Z1。发生分区后，可能在分区的一侧有 A, C, A1, B1, C1, 而另一侧有 B 和 Z1。Z1 能写入 B，B 也接受其写入。如果分区持续的时间足以让 B1 升级为该分区的多数端的主服务器，那么 Z1 在此期间发送给 B 的写入将丢失。

### 16. Redis 事务的了解。 CheckAndSet 操作实现乐观锁

**简介：**

+ [Redis 事务](https://redis.io/topics/transactions)里所有的命令都会 **被序列化** 然后 **被顺序执行**，在事务执行过程中，不会再为其它客户端的请求提供任何服务，从而保证事务中的所有命令原子性执行。Redis 的事务也是原子的，要么全部不执行，要么全都执行。

+ 事实上在执行事务中的命令发生错误时，**Redis 不会进行回滚**，而是继续向下执行完剩下的命令。因为 Redis 命令可能失败的原因只可能是语法错误或者使用了错误的数据类型。失败的命令会返回失败的结果，因此失败往往在开发时候就发现了，不会出现在生产中。Redis 会因为没有回滚而变得 **更简单更快**。

**使用：**

```shell
> MULTI          # 收到 OK 后，意味用户可以发出多个命令
OK
> INCR foo       # 命令排队
QUEUED           # 回复 QUEUED 表示命令已开始正常排队，如果返回错误，则应该中止该事务并将其丢弃
> INCR bar      
QUEUED
>EXEC            # 执行所有命令，返回答复数组，每个元素都是单个命令的答复，顺序与发出的命令顺序相同
1)(integer) 1
1)(integer) 1    # 假如在第二部执行之前，第一步执行之后，Redis 服务器挂了，此时你使用的还是 AOF 持久化机制，Redis 重启时会发生错误然后退出。
                 # 这时可以使用 `redis-check-aof` 修复日志文件，删除之前注册了的部分事务，以便服务器可以重新启动。
```

```shell
> SET foo 1
OK
> MULTI
OK
> INCR foo
QUEUED
> DISCARD        # 中止事务，不执行任何命令
OK
> GET foo
"1"
```

#### 16.1 使用 check-and-set 操作 实现 乐观锁

乐观锁是为了解决多客户端同时对一个 key 进行操作，导致操作未生效，或者操作结果错误的情况。乐观锁就是认为不会发生并发问题，因此不会对数据上锁，如果数据发生变化，则当前操作失效。

`WATCH` 命令被用来提供 check-and-set 行为。具体使用如下：

```shell
WATCH mykey            # watch 将检测其更改，若在 EXEC 之前至少修改了一个监视键，则当前事务会被中止。
val = GET mykey
val = val + 1
MULTI
SET mykey $val
EXEC                   # 若事务中止，EXEC 返回 null 答复以通知该事务失败
```

ps:

一个 Redis 脚本 就是 事务性的，所有的事务能做的，用 Redis 脚本也可以做。且会更简单更快速，但是由于 事务 先于 脚本存在，因此删除不太合理。但如果有一天所有的用户都是用 Redis 脚本，Redis 表示可能会选择弃用或删除事务。

### 17. Redis 有序集合 zset 底层是如何实现的？

由于需要数据 **有序**，所以马上想到 list 和 array。现在看看插入数据时候这俩种数据结构的性能：

**Array**: 由于在查找插入位置的时候可以使用二分查找，因此时间复杂度是 O(lgN)，在插入数据的时候，所有的插入位置右边的数据要右移，因此是 O(N)

**List**: 查找插入位置的时候无法用二分，因此是 O(N), 但是插入很快，只要 O(1) 即可。

对于百万，千万的数据来说，还是太慢了。因此我们选择 **跳跃表(skiplist)**，跳表是一种 **基于有序链表** 的扩展。

**怎么能快速查找一个有序链表的某一个节点呢？**

```markdown
可以利用类似索引的思想，**提取** 出链表中部分的 **关键节点**，比如所有值为奇数的节点。这样就可以确定节点范围，然后再找到具体的位置。有了这样的思想，不难想到如果在第一层节点基础上进一步提取，**保证每一层是上一层节点数的一半**。于是有了第二层节点。这样当节点很多的时候，比较次数就会变成原来的 1/4。这样多层链表的结构，就是所谓的 **跳跃表**。每个索引节点都包含两个指针，一个向下，一个向右。
```

**那么当插入节点的个数越来越多，怎么选择关键节点插入节点，怎么淘汰关键节点呢？**

```markdown
跳跃表的设计者，随机决定新节点是否提拔，每向上提拔一层的几率是 50%。就和 抛硬币 一样。原因是因为跳跃表的删除和添加是无法预测的，因此很难有一种算法保证跳跃表的索引分布始终均匀。
```

**跳表的时间复杂度呢？**

```markdown
查找、插入、删除 都是 O(logN) 
```

**空间复杂度呢？**

`O(N)`

**跳表和二叉树的区别？**

```markdown
跳表的优点是维持平衡的成本低，完全靠随机。二叉树在多次插入删除以后，需要 rebalance 来重新调节结构平衡。
```

### 18. Redis 什么命令可以多次 set? 如果一次性存储大量的数据(百万级别)呢？

**A1**: `MSET key1 "Hello" key2 "World"`

**A2**: 

```markdown
使用 pipeline, 因为单个命令会存在一个接受服务端返回结果的过程，pipline 则是将多个命令发送到服务器，不需要等待一个一个的应答。但是 pipeline 只适用于一堆连续但不相关的命令，这时可以使用 scripting 的功能规避这个局限性。并且 pipeline 期间独占一个 connection, 不能执行其它非管道类型的操作。为了不干扰到链接中的其它操作，可以为 pipeline 新建链接。
```

### 19. Redis 分布式锁

[小米信息部计数团队](https://xiaomi-info.github.io/2019/12/17/redis-distributed-lock/)

**Redis 分布式锁来解决并发仍存在一些困难，只能作为缓解并发的一种手段，如果要完全解决并发问题，仍需要数据库防并手段。**

**实现命令**

```shell
SETNX key value                  # 当键不存在时，对键设置操作并返回成功，否则返回失败
DEL key                          # 通过删除键值对来释放锁
EXPIRE key timeout               # 设置锁的超时时间，保证即使锁没有被显示释放，在一定时间后也会自动释放
```

**19.1 SETNX 和 EXPIRE 的非原子性**

```markdown
如果 SETNX 成功 && 设置锁超时时间但还未成功，在这过程中，服务器挂调、重启、网络问题，导致 EXPIRE 命令没有执行，锁没有设置超时时间就会变成死锁。

解决方法：
1. redis set 有一个非常复杂的参数可以将 setnx 和 expire 合成一条指令来用
jedis.set(key, System.currentTimeMillis() + "", "NX", "EX", seconds); // 这个是 java 实现的
2. redis 的事务可以解决
```

**19.2 锁被误解除**

```markdown
如果线程 A 成功获取到了锁，并设置了过期时间 30s, 但是线程 A 的执行时间超过了 30s，锁过期就自动释放了，此时线程 B 拿到了锁；随后 A 执行完成，这时 A 使用了 DEL 命令来释放锁，但此时线程 B 加的锁还没有执行完成，线程 A 释放的其实是 B 的锁。

解决方法:
1. 通过在 value 中设置当前线程加锁的标识，在删除之前验证 key 对应的 value，来判断这个锁是否是当前线程所持有的。
```

**19.3 超时解锁导致并发**

```markdown
解决方法：
1. 将过期时间设置得足够长，确保代码逻辑在锁释放之前能够执行完成
2. 为获取锁的线程增加守护线程，为将要过期但是未释放的锁增加有效时间，这样可以保证锁不会自动过期删除。这样主线程不死，守护线程就会一直给锁增加有效时间，别的进程就不会拿到这个锁了
```

**19.4 无法等待锁释放**

```markdown
解决方式：
1. 客户端可以轮询，直到获取到锁。这种方式消耗服务器资源。
2. 使用 redis 的 pub/sub，当获取失效时，订阅锁释放的消息，当锁成功释放，发送锁释放消息。
```

**19.5 不可重入性**

```markdown
当线程在持有锁的情况下再次请求加锁，如果一个锁支持一个线程多次加锁，那么这个锁就是可重入的。如果一个不可重入锁被再次加锁，由于该锁已经被持有，再次加锁会失败。Redis 可通过对锁进行重入计数，加锁时加 1，解锁时减 1，当计数归 0 时释放锁。
```

**19.6 主备切换**

```markdown
当客户端 A 成功加锁，指令还未同步，此时主节点挂了，从节点提升为主节点了，新的节点没有锁的数据，客户端 B 就可以加锁成功。
```

**19.7 集群脑裂**

```markdown
指因为网络问题，导致 master 节点、slave 节点、sentinel 的集群出现不同的网络分区，某一个分区里的 sentinel 集群无法感知到 master 的存在，于是将 slave 节点提拔为 master 节点，导致出现两个 master 节点。

解决方式：
当有不同客户端连接不同的 master 节点时，两个客户端可以同时拥有一把锁。
```

### 20. 你了解最近点的 KV、DB 读写模式吗？

```markdown
最经典的 缓存+数据库读写 模式，就是 cache aside pattern
1. 读的时候，先读缓存，缓存没有的话，就读数据库，然后取出数据放入缓存，同时返回响应
2. 更新的时候，先更新数据库，然后再删除缓存
```

**20.1 为什么是删除数据库，而不是更新缓存？**

```markdown
1. 删除缓存比更新缓存更加简单，使用更新缓存更容以出现读写不一致的问题。
2. 另外更新缓存的代价有时候是很高的，对于比较复杂的缓存数据计算的场景，频繁修改一个缓存涉及的多个表，缓存也频繁地更新。然而，这个缓存可能并不会这么频繁地被访问到。
```

### 21. Redis 和 Memcached 有啥区别？为什么选择用 Redis 作为你们的缓存中间件？

```markdown
1. Redis 支持复杂的数据结构，支持更丰富的数据操作。
2. Redis 原生支持集群模式，在 Redis 3.x 版本中，便能支持 Cluster 模式，而 Memcached 没有原生的集群模式，需要依靠客户端来实现往集群中分片写入数据。
3. 由于 Redis 只使用单核，Memcached 可以使用多核，所以平均每个核上 Redis 存储小数据的性能比 Memcached 性能更高。在 100k 数据以上，Memcached 性能要高于 Redis，虽然 Redis 最近也在存储大数据的性能上进行优化，但是比起 Memcached 还是稍有逊色。
```

### 22. Redis 的线程模型了解吗？

```markdown
Redis 内部使用文件时间处理器 file_event_handler，这个文件事件处理器是单线程的，所有 Redis 才叫单线程模型。它采用 IO 多路复用机制同时监听多个 Socket，根据 Socket 上的事件来选择对应的事件处理器进行处理。

文件事件处理器的结构包含四个部分：
1. 多个 Socket
2. IO 多路复用程序
3. 文件事件分派器
4. 事件处理器(连接应答处理器、命令请求处理器、命令回复处理器)
```

### 22. Redis 的分片机制

```markdown
Redis Cluster 采用虚拟哈希槽分区
在 Redis 集群中，哈希槽 其实就是虚拟的很小粒度的分区，所有的键根据哈希函数映射到 0 ~ 16383 整数槽内，每个key通过CRC16校验后对16384取模来决定放置哪个槽(Slot)，每一个节点负责维护一部分槽以及槽所映射的键值数据。
```

#### Redis 为什么使用 16384 个哈希槽呢？

[why 16384](https://zhuanlan.zhihu.com/p/99037321)

### 23. 在集群模式下，Redis 的 key 是如何寻址的？分布式寻址都有哪些算法？了解一致性 hash 算法吗？

**A1: 集群模式下，Redis 的 key 是如何寻址的？**

```markdown
1. client 可能会挑选任意的一个 Redis 实例去发送命令，实例收到命令以后执行 步骤2。
1. 计算 hash slot, 具体的就是对 key 进行 crc16 计算，然后对 16384 进行取模。
2. hash slot 的查找，由于节点间通过 gossip 协议进行数据交换，每一个节点都知道每个 hashslot 在哪个节点上。
```

**A2: 分布式寻址都有哪些算法？**

```markdown
1. hash 算法
计算 hash 值，然后对节点数取模，打在不同的 master 节点上。所有请求过来，都会基于最新的剩余 master 节点数取取模，然后尝试获取数据。这样会导致大部分的请求过来，都无法拿到有效的缓存，导致大量的流量涌入数据库。存在大量的缓存重建。这个算法也可以实现简单的负载均衡。
2. hash slot 算法
略
3. 一致性 hash 算法
略
```

**A3: 一致性 hash 算法是什么？**

```markdown
1. 一致性 hash 算法通过一致性哈希环的数据结构来实现，这个环的起点是 0，终点是 2^32 - 1。起点与终点连接，顾环的整数范围是 [0, 2^32 - 1]。
2. 现在来了一个 key, 计算其 hash 值。hash 值的范围在 [0, 2^32 - 1]
3. 接着同样对服务器的 IP 或 主机名作为键计算其 hash 值。这样每台服务器就能确定其在哈希环上的位置。
4. 将对象和服务器都放置到同一个哈希环后，在哈希环上顺时针查找距离这个对象的 hash 值最近的机器，就是这个对象的所属机器。
```

### 24. 一致性 hash 算法有什么好处？

1. 保证了在扩容或缩容的时候，数据存储的改变很少，最多影响到当前新增节点，和圆环上的前一个节点之间的那些对象数据上。
   
   PS: 针对扩容的场景，是为了分担集群中节点的压力，但是可能会出现，新增节点之分担到个别节点的数据，其它节点压力还是很大。那么此时可以引入虚拟节点，解决负载不均衡的问题，即把每台物理服务器虚拟为一组虚拟服务器，再将虚拟服务器放置在圆环上。

### 25. 如果 Redis 里有1亿个 key, 其中有 10w 个 key 拥有固定前缀。如何找出来呢？

```shell
keys {prefix}*
```

### 26. 这时如果这个 Redis 正在给线上的业务提供服务，使用 keys 指令会有什么问题?

```markdown
Redis 是单线程的。keys 指令会导致线程阻塞一段时间，线上业务会出现停顿，直到 keys 指令执行完毕，服务才能恢复。这时可以使用 scan 指令。
1. scan 指令可以无阻塞地提取出指定模式的 key 列表
2. 会有一定重复的概率，在客户端进行去重即可
3. 整体花费的时间会比 keys 指令要长
4. 不过，增量式迭代命令也不是没有缺点的：举个例子， 使用 SMEMBERS 命令可以返回集合键当前包含的所有元素， 但是对于 SCAN 这类增量式迭代命令来说， 因为在对键进行增量式迭代的过程中， 键可能会被修改， 所以增量式迭代命令只能对被返回的元素提供有限的保证

用法 -  SCAN 命令每次被调用之后， 都会向用户返回一个新的游标， 用户在下次迭代时需要使用这个新游标作为 SCAN 命令的游标参数， 以此来延续之前的迭代过程。当服务器向用户返回值为 0 的游标时， 表示迭代已结束：
> scan 0
{cursor}
> scan {cursor}
```

### 27. 使用过 Redis 做异步队列吗? 你是怎么用的?

```markdown
一般使用list结构作为队列，rpush生产消息，lpop消费消息。当lpop没有消息的时候，要适当sleep一会再重试。
```

### 28. 如果对方追问不可以 sleep 呢？

```markdown
list还有个指令叫 blpop，在没有消息的时候，它会阻塞住直到消息到来。
```

### 29. 如果对方追问能不能生产一次消费多次呢？

```markdown
使用pub/sub主题订阅者模式，可以实现 1:N 的消息队列。
```

### 30. pub/sub 有什么缺点呢？

```markdown
在消费者下线的情况下，生产的消息会丢失，得使用专业的消息队列。如 RabbitMQ、RocketMQ等。
```

### 31. 那 Redis 如何实现延时队列？

```markdown
延时队列是指，在内部的元素只有延时期满，方可取出。那么用 Redis 的实现可以使用 aortedset，拿时间戳做 score，消息内容作为 key, 然后用 zadd 调用来生产消息。消费者用 zrangebyscore 指令来获取 N秒 之前的数据轮询进行处理。
```

### 32. Redis 的同步机制了解吗？

```markdown
Redis 可以实现主从同步、从从同步。第一次同步时，主节点做一次 bgsave，同时将后续修改的操作记录记录到内存重写 buffer，待完成后将 RDB 文件全量同步到复制节点，复制节点接受完成后将 RDB 镜像加载到内存。加载完成后，再通知主节点将期间修改的操作记录同步到复制节点，进行重放，然后完成同步过程。后续的增量数据通过 AOF 日志同步即可，有点类似数据库的 binlog。
```

### 33. 是否使用过 Redis 集群，集群的高可用怎么保证，集群的原理是什么？

```markdown
Redis Sentinal 着眼于高可用，在 master 宕机时会自动将 slave 提升为 master，继续提供服务。
Redis Cluster 着眼于扩展性，在单个 Redis 内存不足时，使用 Cluster 进行分片存储。
```

### 34. 缓存和数据库双写一致问题？

```markdown
当出现写操作或者删除操作的时候，修改的是 MySQL 里的值，在还没有删除 Redis 里的缓之前，就有读请求过来了，这时读到的缓存里的数据和 MySQL 里就不一致了。原因就是因为这两步不是原子性的。

1. 先更新 MySQL 的时候就失败了，之间抛出异常，然后 rollback, 抛出异常。不去进行第二步。
2. 可以先删除 Redis 缓存，这样如果第一步失败了，数据库和缓存数据都是一致的。
3. 并发情况下，前面两种方式都会存在问题，可以利用消息队列来实现消息最终一致性的保证，利用消息队列的重试机制来保证两者都更新成功，如果多次消费失败，可能是由于 网络 或者 Redis 挂了，需要添加告警提醒。
```

### 35. 简述一下 Redis 常用数据结构及实现？

*首先，在 Redis 内部，会使用一个 RedisObject 表示所有的 key 和 value。*

+ **string - SDS 简单动态字符串**

```markdown
1. 增加了 len 来表示当前字符串的长度，时间复杂度是 O(1)。

2. 自动扩展空间，当 SDS 需要对字符串进行修改时，首先借助于 len 和 alloc 检查空间是否满足修改所需的要求，如果空间不够，SDS 会自动扩展空间。

3. 有效降低内存分配次数，SDS 使用了 空间预分配 和 惰性空间释放 机制，简单理解就是每次在扩展时是成倍地多分配的，在缩容的时候也是先留着，并不是正式归还给 OS 的。

4. 二进制安全，C语言只能保存 ascii 码，图片、音频等信息无法保存。SDS 是二进制安全的，写入什么读取就是什么，不做任何过滤和限制。
```

+ **字典是如何实现的？ Rehash 了解吗？**

```markdown
redis 中的字典有两个用途：
1. 实现数据库键空间，数据库的所有 key 和 value 也组成了一个全局字典。
2. 用作 redis - hash 结构的数据会用到的底层实现。

Redis 中字典的底层实现哈希表实现的，源码里是一个 dictEntry 数组，每个 dictEntry 里面存的就是 kv 键值对，将 key 通过 hash 函数计算，然后存入数组。另外使用的是 "数组+链表" 的链地址法 解决部分的哈希冲突。

当 hashmap 中多次出现哈希冲突，超过了某个域值时，处于链表性能的考虑，要进行扩容操作，rehash 是在哈希表扩容和缩容的时候用到的，意思是渐进式搬迁。这个过程是分多次、渐进式地完成的。如果旧的 hashtable 非常庞大，一次性搬迁导致的计算量可能导致服务器会在一段时间内停止服务。

这个过程描述为：
1. 动态分配一块内存，生成一个新的 hashtable, h1，此时字典同时有两个 hashtable
2. 在字典中维持一个索引计数器(rehashidx)，并将它的值设置为 0，表示 rehash 工作正式开始
3. rehash 期间如果发生任何 插入、更新、删除 操作，都会判断哈希表是否正在 rehash,如果是则帮助执行一次。且新添加的 key 会一律被保存到 h1 中。如果查找的话，就会现在 h1 中找，如果没有的话，就去 h0 中找。工作完成后，将 rehashidx ++
4. 当 h0 中的键值对全被 rehash 到 h1, 将 rehashidx 设置为 -1，表示 rehash 操作已完成
```

**扩容缩容的条件？**

```markdown
扩容：
正常情况下，当 hash 表中的元素个数等于第一维数组的长度时，就会开始扩容了，扩容的新数组是原数组大小的 2 倍。如果 redis 正在做 bgsave，为了减少内存，尽量不去选择扩容，当 hash 表大小达到了第一维数组长度的 5 倍。就会强制扩容

缩容：
元素个数低于数组长度的 10%，缩容不会考虑 Redis 是否在做 bgsave。
```

+ **List 的底层实现是 ziplist 压缩列表 + 双端链表**

+ **Hash 的底层实现是 hashtable + ziplist**

+ **Set 的底层实现是 intset + hashtable**

+ **Sorted Set 的底层实现是 跳表 + ziplist**

### 36. Redis 中的布隆过滤器使用过吗？

```markdown
首先 Redis 中的布隆过滤器底层实现是一个二进制位数组，每一个元素的值都初始化位 0。然后有多个的 hash 函数，key 通过这些 hash 函数计算出来多个哈希值，然后对位数组的长度取模，再将结果对应数组中的位置都设置为 1。查找的时候也是一样计算取模，然后取看数组中的位置是否都是 1，只要有一个位置不是 1，就代表这个元素不存在。

总而言之，如果布隆过滤器中查找出来不存在，则一定不存在。但是如果查出来存在，则不一定就存在。

Redis 官方提供的布隆过滤器用到了 Redis4.0 提供了插件功能之后才正式登场的。布隆过滤器作为一个插件加载到 Redis Server 中，给 Redis 提供了强大的布隆驱虫功能。
```

```shell
> docker pull redislabs/rebloom
> docker run -p 6379:6379 redislabs/rebloom
> redis-cli
> bg.reserve                     # 自定义参数的布隆过滤器
> bf.add codehole user1
> bf.exists codehole user2
> bf.madd codehole user3 user4 user5
> bf.mexists codehole user3 user4 user5
```
