# 消息中间件面试问题

##### Q1. 为什么使用消息队列？消息队列的优缺点？kafka、activemq、rabbitmq、rocketmq 都有什么样的优缺点

+ 面试官角度分析：
  + 1. 你知不知道你们系统里为什么要用 消息队列 这个东西？因为什么好处而用？
    2. 为什么具体选择某一款 MQ？

+ 面试官想了解的：
  + 1. 什么样的业务场景下
    2. 用了 MQ 的好处
    3. 不用 MQ 的麻烦

---------------------------

**消息队列常见使用场景核心的有三个：解耦、异步、削峰。**

### 解耦

场景：

​	一个系统或一个模块，调用了多个系统或者模块，且相互之间的调用非常的复杂。但是这个调用并不需要直接同步调用接口，可以用 MQ 进行异步化解耦。
```markdown
在安全运营平台中，每个告警都是一个 producer, 他们需要将告警数据以规范的格式打入安全运营平台。其中会涉及到一些重复告警的归并，低级别告警的自动处置等等。因此将公共功能抽象出来成为服务，即 worker。
告警对于安全运营平台来说是非常重要的，如果不用 MQ, 则 worker 进程如果死亡就会造成告警丢失。但是将告警存在 MQ 中则不用担心太多，不论 worker 的状态如何，只要没有消费掉的，就还在 MQ 里面。那么对于 producer 来说，就不用关注 worker 进程的状态，是活着，还是已经死了。
```

### 异步

场景：

​	 系统 A 接受一个请求，需要再自己本地写库，还需要在系统 BCD 三个系统写库。自己本地写库需要 3ms, BCD 写库需要 300ms, 450ms, 200ms, 最终总时长：953ms, 接近 1s, 时间太长。
​    (一般互联网类的企业对用户的直接操作一般要求每个请求都必须在 200ms 内完成，1s 的操作几乎不可接受)
```markdown
文中是放置三个 MQ, 然后把原本防止在 系统A 的写库动作，分别放到 BCD 三个系统中，让它们各自取 MQ 里的数据进行写库。这样时间就可以缩短为原来的 1/3 了。
我想了一下，在安全运营平台中，由于告警很多(也就是生产者很多)，告警是有实效性的，也就要保证 worker 要即使消费掉产生的告警。且要满足不重复消费，同时对告警进行去重、归并 等操作。如果没有 MQ，也能实现，但是多进程访问共享资源就要加锁，涉及到锁的竞争，还有进程间通信，实现起来会很复杂。但是 RabbitMQ 解决了这个问题。但是我认为这并不是 MQ 作为解决同步提供异步而出现的原因，不太理解。
```

### 削峰

场景：

​	每天 0 点到 11 点，系统 A 风平浪静，每秒并发请求数量就 100 个。但是 11 点到 1 点，每秒并发请求的数量就会增加至 1W 个。但是系统最大的处理能力就只有 1000 qps。

```markdown
如果每秒 5000 个操作请求涌进 系统A， 但是 系统A 的处理能力最多每秒 2000 个， 因为 MySQL 每秒处理 2000 个请求就差不多了，如果 5000 个可能会把 MySQL 搞崩。
如果使用了 MQ 的话，虽然在短暂的高峰期内会形成积压，但是这是可以接受的。并不会影响到 系统A 和 MySQL 的正常消费。
```

-------------

### MQ 的缺点

使用 MQ 以后，一旦 MQ 崩溃，获取数据的相关系统都会受到影响。但是如果是提供接口给别人调取，则不用担心这些。

异步的缺点就是无法保证消息的一致性，有些 MQ 也无法保证消息没有被重复消费。另外三写数据还需要注意数据一致性的问题。这个我认为不是 MQ 带来的，是异步带来的。这篇文章还是写的不太好。

------------------------

### KAFKA

+ 单机吞吐量
  + **10W** 级别，这是 kafka 的最大优点，吞吐量高。一般进行实时数据的计算，日志采集等场景。
+ topic 的数量对吞吐量的影响
  + topic 从**几十个到几百个**的时候，吞吐量会大幅下降。所以在同等机器下，topic 的数量不要过多。否则要增加机器。
+ 时效性
  + 延迟在 **ms 级** 以内
+ 可用性
  + 非常高，kafka 是**分布式的**，一个数据多个副本，少数机器会宕机，不会丢失数据，不会导致不可用。
+ 消息可靠性
  + 经过参数优化配置，消息可以做到 **0 丢失**。
+ 功能支持
  + **功能较为简单**，主要支持简单的 MQ 功能。
+ 总结
  + 仅仅提供较少的核心功能，但是提供超高的吞吐量，ms 级的延迟，极高的可用性以及可靠性，分布式可以任意扩展。唯一的劣势就是可能消息重复消费，对数据的准确性只会造成微乎其微的影响，在大数据领域以及日志采集中，这点轻微的影响可以忽略。

-------------------------

### RabbitMQ

+ 吞吐量
  + **万级**
+ topic 数量对吞吐量的影响
  + 无
+ 时效性
  + **微秒级别，延迟是最低的。**
+ 可用性
  + 高，基于**主从架构**实现高可用性。
+ 消息可靠性
  + 无？
+ 功能支持
  + 基于 erlang 开发，并发能力强，性能极好，延迟极低，功能较完备。
+ 总结
  + 开源提供的管理界面非常棒，好用，且社区活跃度相对较好，几乎每个月都发布几个版本。基于 erlang 开发意味着如果出问题你看 erlang 源码很难。rabbitMQ 的集群动态扩展会很麻烦。

----------------------------

### RocketMQ

+ 单机吞吐量
  + **10W 级**
+ topic 数量对吞吐量的影响
  + 可以达到几百甚至几千的级别，且吞吐量只会有**较小**幅度的下降
+ 时效性
  + **ms 级**
+ 可用性
  + 非常高，**分布式架构**
+ 消息可靠性
  + 经过参数优化配置，可以做到消息 **0 丢失**
+ 功能支持
  + 较为完善，还是分布式的，扩展性好
+ 总结
  + 接口简单易用，日处理消息高达上百亿，性能好，扩展性好，支持大规模 topic 数量。支持复杂的 MQ 场景。且阿里出品都是 java 写的，用户可以自己阅读远吗。

------------------------------------

### RabbitMQ 的高可用性

​		RabbitMQ 有三种模式：单机模式、普通集群模式、镜像集群模式。

+ **单机模式**

+ **普通集群模式**

  意思就是多台机器上启动多个 RabbitMQ 实例，每个机器都会启动一个，但是你创建的 Queue 只会在一个 RabbitMQ 上。但是每个实例都会同步 Queue 的元数据。你消费的时候，实际上如果连接到了另一个实例上，那个实例就会从 Queue 所在的实例上拉数据过来。这个方案主要是为了服务提高吞吐量用的，就是说让集群中多个节点来服务某个 Queue 的读写操作。

  缺点有：

  	1. 拉取数据的开销
   	2. 单例性能的瓶颈
   	3. 如果放 Queue 的那个实例宕机了，会导致接下来其它实例无法从这个实例拉去数据。如果开启了消息持久化，消息不一定会丢，但是得等这个实例恢复了，才能继续从这个 Queue 拉取数据。

+ **镜像集群模式**

  创建的 Queue， 无论是元数据 还是 Queue 里的消息都会存在于多个实例上，每次写消息到 Queue 的时候，都会自动把消息和其它实例里的 Queue 进行消息同步。这样的好处就是，不怕单个机器宕机。**启用的时候** 在后台管理平台新增一个策略，指定要求数据同步到所有节点或者部分节点。再次创建 Queue 的时候就会应用这个策略了。

  缺点：

  	1. 性能开销太大，网络带宽压力等
   	2. 没有扩展性，如果某个 Queue 负载很重，加机器也没用，加机器也会包含这个 Queue 的负载。

  ---------------------

  ### Kafka 的高可用性

  ​		多个 broker 组成，每个 broker 是一个节点，创建一个 topic, 这个 topic 可以划分为多个 partition, 每个 partition 可以存在于不同的 broker 上，每个 partition 就放一部分的数据。这个就是分布式消息队列，一个 topic 里的数据分布在多太机器上。

  ​		实际上 RabbitMQ 之类的并不是分布式消息队列，就是传统的消息队列。他一个 Queue 里的数据都是放在一个节点里的。

  ​		Kafka 8.0 之后，提供了 HA(High Availability) 机制，就是 replica 副本机制。每个 partition 的数据都会同步到其它机器上，形成自己的多个 replica 副本。然后所有的 replica 会选举一个 leader 出来，生产和消费都和这个 leader 打交道。然后其它的 replica 就是 follower, 写的时候 leader 负责把数据同步到所有的 follower 上，读的时候只要读 leader 即可。这时候只要某个机器宕机了，这台机器上的 partition 在其它机器上都是有副本的，如果里面有某个 partition 的 leader, 此时只要重新选举即可。

  ​		**写数据时，** 生产者就写 leader, leader 将数据落地到磁盘上，其它 follower 主动从 leader 这里来 pull 数据。一旦所有 follower 同步好数据，就会发送 ack 给 leader, leader 收到所有 follower 的 ack 以后，就会返回 “写成功” 的消息给生产者。(这个只是其中的一种模式)。

  ​		**读数据时，** 只会从 leader 这里读，但是只有一个消息已经被所有 follower 都同步成功返回 ack 的时候，这个消息才会被消费者读到。

  --------------

  ### 如何保证消息不被重复消费？如何保证消息消费时的幂等性？(以Kafka举例)

  Kafka 有一个 offset 的概念，每个消息写入都会有一个 offset 代表其序号，consumer 消费后每隔一段时间就会把自己消费过的 offset 提交一下。如果说在提交 offset 之前系统就宕机了，就会导致少数的消息会被重复消费。重复消费不可怕，可怕的是没有考虑如何保证幂等性。如果是存 MySQL 的，比如唯一性约束，如果是存 Redis 的 Set, 则是天然幂等性。这个要具体场景具体分析。

  -------------------------------

  ### 如何保证消息的可靠传输(如何处理消息丢失的问题)？

  场景：比如说计费系统。

  这里要从两方面考虑，1. MQ 自己弄丢了。2. 我们消费的时候弄丢了。3. 生产者就没有把数据放进队列。

  #### RabbitMQ

  + 生产者弄丢

    + 可能在发送数据的时候因为网络等问题，导致数据在半路失踪。
    + 解决方案：
      + 1. 选择 RabbitMQ 的事务功能（**同步的**），在生产者发送数据之前开启 RabbitMQ 事务，然后再发送消息，如果消息没有被 RabbitMQ 接收到，则会接收到异常报错，此时可以回滚事务。但是这样吞吐量会下降，消耗性能。
      + 2. 开启 RabbitMQ 的 confirm 模式（**异步的**），每次写的消息都会分配一个唯一 ID，如果写入了 RabbitMQ 中，则会收到 一个 ack 消息，表示消息写入。如果 RabbitMQ 没能处理这个消息，则会回调你的一个 nack 接口，告诉你消息接受失败，可以重试。可以结合这个机制在自己的内存里维护每个消息 ID 的状态。

  + RabbitMQ 弄丢
    + 开启数据持久化，哪怕 RabbitMQ 自己挂了，恢复以后会自动读取之前存储的数据，一般数据不会丢，除非说还没持久化之前就挂了。
    + 解决方案
      + 1. 创建 Queue 的时候将其设置为持久化的，这样就可以保证 RabbitMQ 持久化 Queue 的元数据，但是不会持久化 Queue 里的数据。
      + 2. 发送消息的时候将消息的 deliveryMode 设置为 2。必须同时设置以上两个持久化才行。这样只有在持久化以后才将 ack 返回给 生产者，生产者如果没有收到 ack, 还可以重发。

  + 消费者弄丢
    + 刚消费到，但是却没有处理，进程就挂了。
    + 解决方案
      + 1. 关闭 RabbitMQ 的自动 ack 机制。确保当程序确实处理完的时候，才会发送 ack, 而不是读到自动发送 ack。

  #### Kafka

  + 消费端弄丢
    + 消费到了消息，消费者自动提交了 offset。
    + 解决方案：
      + 依旧是自己手动提交 offset。但是可能会重复消费，因此要自己保证好幂等性。
  + Kafka 弄丢
    + kafka 的某个 broker 宕机，某些 follower 的数据还没有完全同步好，但是这时候 leader 就挂了，但是又在没有同步好的 follower 里面新选了一个 leader, 不就丢失了一些数据么。
      + 解决方案
        + 1. 给 topic 设置 replication.factor 参数：这个值必须 > 1。要求每个 partition 必须至少有两个副本。
        + 2. 在 kafka 服务端设置 min.insync.replicas 参数：这个值必须 > 1。要求 leader 至少感知到有至少一个 follower 还跟自己保持联系，这样才能确保 leader 挂了还有一个 follower。
        + 3. 在 producer 端设置 acks=all， 这个是要求每条数据，必须是写入所有 replica 之后，才能认为是些成功了。
        + 4. 在 producer 端设置 retries=MAX：要求一旦写入失败，就无限重试。
  + 生产者不会弄丢数据
    + 一旦 acks=all 以后，要求 leader 接收到消息，且，所有的 followers 都同步到了消息，才算是写入成功。如果不满足就会要求生产者无限重试。因此不可能会弄丢。

------------------------------------------

### 如何保证消息的顺序性？

我举个例子，我们以前做过一个mysql binlog同步的系统，压力还是非常大的，日同步数据要达到上亿。mysql -> mysql，常见的一点在于说大数据team，就需要同步一个mysql库过来，对公司的业务系统的数据做各种复杂的操作。

你在mysql里增删改一条数据，对应出来了增删改3条binlog，接着这三条binlog发送到MQ里面，到消费出来依次执行，起码得保证人家是按照顺序来的吧？不然本来是：增加、修改、删除；你楞是换了顺序给执行成删除、修改、增加，不全错了么。

本来这个数据同步过来，应该最后这个数据被删除了；结果你搞错了这个顺序，最后这个数据保留下来了，数据同步就出错了。

##### 如何保证消息的顺序性呢？

不管是 RabbitMQ 还是 Kafka, 都是搞成 一个 Queue, 一个 Consumer 就可以。要保证只有一个线程在做写入的动作。就可以保证数据的顺序。

-------------------------------------

### 如何解决消息队列的延时以及过期失效的问题？消息队列满了以后怎么处理？几百万的消息堆积该怎么解决？

##### 1）大量消息在 MQ 里积压了几小时还没解决？

​		紧急扩容。具体的描述看 (一言难尽)[https://blog.csdn.net/qq_26545305/article/details/108203087]

​		我总结一下：

		1. 先修复 consumer 的问题，然后将现在所有的 consumer 停掉。
  		2. 再新建一个Topic， 在该 Topic 下新建 十几个 Queue。
    	3. 搞一个临时分发的 consumer 程序，取消费积压的队列里的几百万条数据，将一个队列里的数据分散压力到那十几个队列中。
      	4. 然后部署上十几个 consumer 去消费这十几个队列里的数据。也就是相当于十几倍的速度去消费了。

##### 2) 假如设置了消息的过期时间，积压以后消息就丢了呢？

批量重导。将丢失的数据 查处啦，手动发到 MQ 里。 = =。ok, fine, 说了等于白说。我还很奇怪，既然不想过期删除就别设置过期时间啊。

-------------------------------------

### 如果让你写一个 MQ，如何进行架构设计？

我都懒得摘抄了，直接复制粘贴了。感觉说的也没有特别好。

**1. 首先这个mq得支持可伸缩性吧，就是需要的时候快速扩容，就可以增加吞吐量和容量，那怎么搞？设计个分布式的系统呗，**

参照一下kafka的设计理念，broker -> topic -> partition，每个partition放一个机器，就存一部分数据。如果现在资源不够了，简单啊，给topic增加partition，然后做数据迁移，增加机器，不就可以存放更多数据，提供更高的吞吐量了？

**2. 其次你得考虑一下这个mq的数据要不要落地磁盘吧？**

那肯定要了，落磁盘，才能保证别进程挂了数据就丢了。那落磁盘的时候怎么落啊？顺序写，这样就没有磁盘随机读写的寻址开销，磁盘顺序读写的性能是很高的，这就是kafka的思路。

**3.其次你考虑一下你的mq的可用性啊？**

这个事儿，具体参考我们之前可用性那个环节讲解的kafka的高可用保障机制。多副本 -> leader & follower -> broker挂了重新选举leader即可对外服务。

**4.能不能支持数据0丢失啊？可以的，参考我们之前说的那个kafka数据零丢失方案**