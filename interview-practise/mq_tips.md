# 消息中间件面试问题

##### Q1. 为什么使用消息队列？消息队列的优缺点？kafka、activemq、rabbitmq、rocketmq 都有什么样的优缺点

+ 面试官角度分析：
  + 1. 你知不知道你们系统里为什么要用 消息队列 这个东西？因为什么好处而用？
    2. 为什么具体选择某一款 MQ？

+ 面试官想了解的：
  + 1. 什么样的业务场景下
    2. 用了 MQ 的好处
    3. 不用 MQ 的麻烦

---------------------------

**消息队列常见使用场景核心的有三个：解耦、异步、削峰。**

### 解耦

场景：

​	一个系统或一个模块，调用了多个系统或者模块，且相互之间的调用非常的复杂。但是这个调用并不需要直接同步调用接口，可以用 MQ 进行异步化解耦。
```markdown
在安全运营平台中，每个告警都是一个 producer, 他们需要将告警数据以规范的格式打入安全运营平台。
其中会涉及到一些重复告警的归并，低级别告警的自动处置等等。因此将公共功能抽象出来成为服务，即 worker。
告警对于安全运营平台来说是非常重要的，如果不用 MQ, 则 worker 进程如果死亡就会造成告警丢失。
但是将告警存在 MQ 中则不用担心太多，不论 worker 的状态如何，只要没有消费掉的，就还在 MQ 里面。
那么对于 producer 来说，就不用关注 worker 进程的状态，是活着，还是已经死了。
```

### 异步

场景：

​	 系统 A 接受一个请求，需要再自己本地写库，还需要在系统 BCD 三个系统写库。自己本地写库需要 3ms, BCD 写库需要 300ms, 450ms, 200ms, 最终总时长：953ms, 接近 1s, 时间太长。
​    (一般互联网类的企业对用户的直接操作一般要求每个请求都必须在 200ms 内完成，1s 的操作几乎不可接受)
```markdown
文中是放置三个 MQ, 然后把原本防止在 系统A 的写库动作，分别放到 BCD 三个系统中，让它们各自取 MQ 里的数据进行写库。这样时间就可以缩短为原来的 1/3 了。
我想了一下，在安全运营平台中，由于告警很多(也就是生产者很多)，告警是有实效性的，也就要保证 worker 要即使消费掉产生的告警。且要满足不重复消费，同时对告警进行去重、归并 等操作。如果没有 MQ，也能实现，但是多进程访问共享资源就要加锁，涉及到锁的竞争，还有进程间通信，实现起来会很复杂。但是 RabbitMQ 解决了这个问题。但是我认为这并不是 MQ 作为解决同步提供异步而出现的原因，不太理解。
```

### 削峰

场景：

​	每天 0 点到 11 点，系统 A 风平浪静，每秒并发请求数量就 100 个。但是 11 点到 1 点，每秒并发请求的数量就会增加至 1W 个。但是系统最大的处理能力就只有 1000 qps。

```markdown
如果每秒 5000 个操作请求涌进 系统A， 但是 系统A 的处理能力最多每秒 2000 个， 因为 MySQL 每秒处理 2000 个请求就差不多了，如果 5000 个可能会把 MySQL 搞崩。
如果使用了 MQ 的话，虽然在短暂的高峰期内会形成积压，但是这是可以接受的。并不会影响到 系统A 和 MySQL 的正常消费。
```

-------------

### 2. MQ 的缺点

```markdown
使用 MQ 以后，一旦 MQ 崩溃，获取数据的相关系统都会受到影响。但是如果是提供接口给别人调取，则不用担心这些。

异步的缺点就是无法保证消息的一致性，有些 MQ 也无法保证消息没有被重复消费。另外三写数据还需要注意数据一致性的问题。这个我认为不是 MQ 带来的，是异步带来的。这篇文章还是写的不太好。
```

------------------------

### 3. KAFKA

+ 单机吞吐量
  + **10W** 级别，这是 kafka 的最大优点，吞吐量高。一般进行实时数据的计算，日志采集等场景。
+ topic 的数量对吞吐量的影响
  + topic 从**几十个到几百个**的时候，吞吐量会大幅下降。所以在同等机器下，topic 的数量不要过多。否则要增加机器。
+ 时效性
  + 延迟在 **ms 级** 以内
+ 可用性
  + 非常高，kafka 是**分布式的**，一个数据多个副本，少数机器会宕机，不会丢失数据，不会导致不可用。
+ 消息可靠性
  + 经过参数优化配置，消息可以做到 **0 丢失**。
+ 功能支持
  + **功能较为简单**，主要支持简单的 MQ 功能。
+ 总结
  + 仅仅提供较少的核心功能，但是提供超高的吞吐量，ms 级的延迟，极高的可用性以及可靠性，分布式可以任意扩展。唯一的劣势就是可能消息重复消费，对数据的准确性只会造成微乎其微的影响，在大数据领域以及日志采集中，这点轻微的影响可以忽略。

-------------------------

### 4. RabbitMQ

+ 吞吐量
  + **万级**
+ topic 数量对吞吐量的影响
  + 无
+ 时效性
  + **微秒级别，延迟是最低的。**
+ 可用性
  + 高，基于**主从架构**实现高可用性。
+ 消息可靠性
  + 无？
+ 功能支持
  + 基于 erlang 开发，并发能力强，性能极好，延迟极低，功能较完备。
+ 总结
  + 开源提供的管理界面非常棒，好用，且社区活跃度相对较好，几乎每个月都发布几个版本。基于 erlang 开发意味着如果出问题你看 erlang 源码很难。rabbitMQ 的集群动态扩展会很麻烦。

----------------------------

### 5. RocketMQ

+ 单机吞吐量
  + **10W 级**
+ topic 数量对吞吐量的影响
  + 可以达到几百甚至几千的级别，且吞吐量只会有**较小**幅度的下降
+ 时效性
  + **ms 级**
+ 可用性
  + 非常高，**分布式架构**
+ 消息可靠性
  + 经过参数优化配置，可以做到消息 **0 丢失**
+ 功能支持
  + 较为完善，还是分布式的，扩展性好
+ 总结
  + 接口简单易用，日处理消息高达上百亿，性能好，扩展性好，支持大规模 topic 数量。支持复杂的 MQ 场景。且阿里出品都是 java 写的，用户可以自己阅读远吗。

------------------------------------

### 6. RabbitMQ 的高可用性

RabbitMQ 有三种模式：单机模式、普通集群模式、镜像集群模式。

+ **单机模式**

+ **普通集群模式**
```markdown
意思就是多台机器上启动多个 RabbitMQ 实例，每个机器都会启动一个，但是你创建的 Queue 只会在一个 RabbitMQ 上。但是每个实例都会同步 Queue 的元数据。你消费的时候，实际上如果连接到了另一个实例上，那个实例就会从 Queue 所在的实例上拉数据过来。这个方案主要是为了服务提高吞吐量用的，就是说让集群中多个节点来服务某个 Queue 的读写操作。

缺点：
1. 拉取数据的开销
2. 单例性能的瓶颈
3. 如果放 Queue 的那个实例宕机了，会导致接下来其它实例无法从这个实例拉去数据。如果开启了消息持久化，消息不一定会丢，但是得等这个实例恢复了，才能继续从这个 Queue 拉取数据。
```

+ **镜像集群模式**
```markdown
创建的 Queue， 无论是元数据 还是 Queue 里的消息都会存在于多个实例上，每次写消息到 Queue 的时候，都会自动把消息和其它实例里的 Queue 进行消息同步。这样的好处就是，不怕单个机器宕机。启用的时候在后台管理平台新增一个策略，指定要求数据同步到所有节点或者部分节点。再次创建 Queue 的时候就会应用这个策略了。

缺点：
1. 性能开销太大，网络带宽压力等
2. 没有扩展性，如果某个 Queue 负载很重，加机器也没用，加机器也会包含这个 Queue 的负载。
```
### 7. Kafka 的高可用性

```markdown
多个 broker 组成，每个 broker 是一个节点，创建一个 topic, 这个 topic 可以划分为多个 partition, 每个 partition 可以存在于不同的 broker 上，每个 partition 就放一部分的数据。这个就是分布式消息队列，一个 topic 里的数据分布在多太机器上。
  
实际上 RabbitMQ 之类的并不是分布式消息队列，就是传统的消息队列。他一个 Queue 里的数据都是放在一个节点里的。
  
Kafka 8.0 之后，提供了 HA(High Availability) 机制，就是 replica 副本机制。每个 partition 的数据都会同步到其它机器上，形成自己的多个 replica 副本。然后所有的 replica 会选举一个 leader 出来，生产和消费都和这个 leader 打交道。然后其它的 replica 就是 follower, 写的时候 leader 负责把数据同步到所有的 follower 上，读的时候只要读 leader 即可。这时候只要某个机器宕机了，这台机器上的 partition 在其它机器上都是有副本的，如果里面有某个 partition 的 leader, 此时只要重新选举即可。
  
写数据时, 生产者就写 leader, leader 将数据落地到磁盘上，其它 follower 主动从 leader 这里来 pull 数据。一旦所有 follower 同步好数据，就会发送 ack 给 leader, leader 收到所有 follower 的 ack 以后，就会返回 “写成功” 的消息给生产者。(这个只是其中的一种模式)。
  
读数据时，只会从 leader 这里读，但是只有一个消息已经被所有 follower 都同步成功返回 ack 的时候，这个消息才会被消费者读到。
```

### 8. 如何保证消息不被重复消费？如何保证消息消费时的幂等性？(以Kafka举例)
```markdown
Kafka 有一个 offset 的概念，每个消息写入都会有一个 offset 代表其序号，consumer 消费后每隔一段时间就会把自己消费过的 offset 提交一下。如果说在提交 offset 之前系统就宕机了，就会导致少数的消息会被重复消费。重复消费不可怕，可怕的是没有考虑如何保证幂等性。如果是存 MySQL 的，比如唯一性约束，如果是存 Redis 的 Set, 则是天然幂等性。这个要具体场景具体分析。
```

### 9. 如何保证消息的可靠传输(如何处理消息丢失的问题)？
```markdown
场景：比如说计费系统。
这里要从两方面考虑，1. MQ 自己弄丢了。2. 我们消费的时候弄丢了。3. 生产者就没有把数据放进队列。
```
#### RabbitMQ
+ 生产者弄丢
  + 可能在发送数据的时候因为网络等问题，导致数据在半路失踪。
  + 解决方案：
    + 1. 选择 RabbitMQ 的事务功能（**同步的**），在生产者发送数据之前开启 RabbitMQ 事务，然后再发送消息，如果消息没有被 RabbitMQ 接收到，则会接收到异常报错，此时可以回滚事务。但是这样吞吐量会下降，消耗性能。
    + 2. 开启 RabbitMQ 的 confirm 模式（**异步的**），每次写的消息都会分配一个唯一 ID，如果写入了 RabbitMQ 中，则会收到 一个 ack 消息，表示消息写入。如果 RabbitMQ 没能处理这个消息，则会回调你的一个 nack 接口，告诉你消息接受失败，可以重试。可以结合这个机制在自己的内存里维护每个消息 ID 的状态。
+ RabbitMQ 弄丢
  + 开启数据持久化，哪怕 RabbitMQ 自己挂了，恢复以后会自动读取之前存储的数据，一般数据不会丢，除非说还没持久化之前就挂了。
  + 解决方案
  + 1. 创建 Queue 的时候将其设置为持久化的，这样就可以保证 RabbitMQ 持久化 Queue 的元数据，但是不会持久化 Queue 里的数据。
    + 2. 发送消息的时候将消息的 deliveryMode 设置为 2。必须同时设置以上两个持久化才行。这样只有在持久化以后才将 ack 返回给 生产者，生产者如果没有收到 ack, 还可以重发。
+ 消费者弄丢
  + 刚消费到，但是却没有处理，进程就挂了。
+ 解决方案
    + 1. 关闭 RabbitMQ 的自动 ack 机制。确保当程序确实处理完的时候，才会发送 ack, 而不是读到自动发送 ack。

#### Kafka  
  + 消费端弄丢
    + 消费到了消息，消费者自动提交了 offset。
    + 解决方案：
      + 依旧是自己手动提交 offset。但是可能会重复消费，因此要自己保证好幂等性。
  + Kafka 弄丢
    + kafka 的某个 broker 宕机，某些 follower 的数据还没有完全同步好，但是这时候 leader 就挂了，但是又在没有同步好的 follower 里面新选了一个 leader, 不就丢失了一些数据么。
      + 解决方案
        + 1. 给 topic 设置 replication.factor 参数：这个值必须 > 1。要求每个 partition 必须至少有两个副本。
        + 2. 在 kafka 服务端设置 min.insync.replicas 参数：这个值必须 > 1。要求 leader 至少感知到有至少一个 follower 还跟自己保持联系，这样才能确保 leader 挂了还有一个 follower。
        + 3. 在 producer 端设置 acks=all， 这个是要求每条数据，必须是写入所有 replica 之后，才能认为是些成功了。
        + 4. 在 producer 端设置 retries=MAX：要求一旦写入失败，就无限重试。
  + 生产者不会弄丢数据
    + 一旦 acks=all 以后，要求 leader 接收到消息，且，所有的 followers 都同步到了消息，才算是写入成功。如果不满足就会要求生产者无限重试。因此不可能会弄丢。

### 10. 如何保证消息的顺序性？
```markdown
我举个例子，我们以前做过一个mysql binlog同步的系统，压力还是非常大的，日同步数据要达到上亿。mysql -> mysql，常见的一点在于说大数据team，就需要同步一个mysql库过来，对公司的业务系统的数据做各种复杂的操作。

你在mysql里增删改一条数据，对应出来了增删改3条binlog，接着这三条binlog发送到MQ里面，到消费出来依次执行，起码得保证人家是按照顺序来的吧？不然本来是：增加、修改、删除；你楞是换了顺序给执行成删除、修改、增加，不全错了么。

本来这个数据同步过来，应该最后这个数据被删除了；结果你搞错了这个顺序，最后这个数据保留下来了，数据同步就出错了。
```
##### 如何保证消息的顺序性呢？
```markdown
不管是 RabbitMQ 还是 Kafka, 都是搞成 一个 Queue, 一个 Consumer 就可以。要保证只有一个线程在做写入的动作。就可以保证数据的顺序。
```

### 11. 如何解决消息队列的延时以及过期失效的问题？消息队列满了以后怎么处理？几百万的消息堆积该怎么解决？

##### 1）大量消息在 MQ 里积压了几小时还没解决？

紧急扩容。具体的描述看 (一言难尽)[https://blog.csdn.net/qq_26545305/article/details/108203087]

```markdown
首先消息队列积压的原因往往是因为 生产者的生产速度 和 消费者的消费速度 不匹配导致的。有可能是因为消息消费失败，反复重试造成的，也可能就是消费者的消费能力太弱了。所以第一件事情就是先定位是哪里出问题了。

1. 如果有 bug, 先处理 bug。如果有一些显而易见的逻辑可以优化，先优化消费逻辑，比如说一条一条插数据库和批量插数据库
2. 新建一个 topic, 创建十几个 queue, 搞一个临时分发消息的 consumer 程序
3. 将现有的 consumer 停掉，然后启动 分发堆积消息的 consumer，取消费积压的队列里的几百万条数据，将一个队列里的数据分散压力到那十几个队列中
4. 部署上十几个 consumer 去消费这十几个队列里的数据。也就是相当于十几倍的速度去消费了
```

##### 2) 假如设置了消息的过期时间，积压以后消息就丢了呢？
```markdown
批量重导。将丢失的数据 查处啦，手动发到 MQ 里。 = =。ok, fine, 说了等于白说。我还很奇怪，既然不想过期删除就别设置过期时间啊。
```

### 12. 如果让你写一个 MQ，如何进行架构设计？

**1. 首先这个mq得支持可伸缩性吧，就是需要的时候快速扩容，就可以增加吞吐量和容量，那怎么搞？设计个分布式的系统呗，**

参照一下kafka的设计理念，broker -> topic -> partition，每个partition放一个机器，就存一部分数据。如果现在资源不够了，简单啊，给topic增加partition，然后做数据迁移，增加机器，不就可以存放更多数据，提供更高的吞吐量了？

**2. 其次你得考虑一下这个mq的数据要不要落地磁盘吧？**

那肯定要了，落磁盘，才能保证别进程挂了数据就丢了。那落磁盘的时候怎么落啊？顺序写，这样就没有磁盘随机读写的寻址开销，磁盘顺序读写的性能是很高的，这就是kafka的思路。

**3.其次你考虑一下你的mq的可用性啊？**

这个事儿，具体参考我们之前可用性那个环节讲解的kafka的高可用保障机制。多副本 -> leader & follower -> broker挂了重新选举leader即可对外服务。

**4.能不能支持数据0丢失啊？可以的，参考我们之前说的那个kafka数据零丢失方案**

### 13. 如何保证消息不丢失？

```markdown
1. 首先生产者发送消息给 broker 以后，需要处理 broker 的响应。如果 broker 返回写入失败等错误消息，需要重试发送。如果多次失败，就需要进行告警了。

2. 存储消息阶段需要在消息刷盘之后再给生产者响应，假设消息写入缓存中就返回响应，那么机器突然断电的话消息就没了，而生产者以为发送成功了。如果 broker 是集群部署，有多副本机制，即消息不仅仅要写入当前 Broker，还需要写入副本之后，再给生产者响应，这样基本就可以保证存储的可靠性了。

3. 消费者需要再取到消息并且真正执行完业务逻辑之后，再发送给 broker 消费成功。

ps: 消息的可靠性增强了，自然性能就下降了，等待消息刷盘、多副本同步后返回都会影响性能。因此还是要看业务，如果是日志的传输丢那么一两条的关系不大，也就没必要等待消息刷盘之后再响应了。
```

### 14. 重复消息怎么处理？

1. **首先我们看看能不能避免消息的重复**

```markdown
对于正常的业务而言，消息重复是不可避免的。

1. 首先生产者不重复发消息是可以做到的，就是不管 broker 的响应，发完就完事了，但是这样消息是完全不可靠的。

2. 即使生产者需要处理 broker 响应，也有可能出现重复。比如，broker 可能已经收到消息了，也返回了响应，但是由于网络原因，生产者没有收到这个响应。这时候就可能会造成生产者又发送一次数据，数据就又重复了。

3. 再比如说 kafka，消费者拿到消息消费了，业务逻辑也走完了，事务也提交了，此时它需要更新 offset 了，然后这个消费者挂了。另一个消费者顶上，这时 offset 还是没有更新，于是新的消费者就会消费到重复的消息，业务流程又重新来一遍。

4. 再比如有多个消费者消费同一条消息，这两个走的不是同一个业务流程，万一出现了 consumer1 走业务流程结束，成功了。这条消息也被别的服务监听了，consumer2 消费失败了，于是要求重发，consumer1 也还是会收到重复消息。
```

2. **既然不能解决发送重复消息和收到重复消息，就只能解决重复消息了，关键点就是 幂等性**

```markdown
幂等首先是数学上的概念，我们理解为同样的参数多次调用同一个接口和调用一次产生的结果是一致的。这个要分场景考虑，看是用强校验还是弱校验。比如和钱有关的，得用强校验。不是很重要的场景就做弱校验。

场景：
用户下单成功后我需要去一个活动页面给他加GMV（销售总额），最后根据他的GMV去给他发奖励。

强校验
1. 比如说，监听到用户支付成功的消息，要去调 GMV 加钱的接口。这时可以调用 加钱接口 后面加一个 加流水接口。做成一个事务，要么一起成功，要么一起失败。每条消息过来，都要带着（订单号 + 业务场景）这样的唯一标识。先去流水表查，如果有这条流水，就不走下面的加钱加流水的流程了。

弱校验：
1. 比如说钉钉群里防止出现重复告警，会把高危告警的 alarm_id 存在 redis, 发钉钉之前先去判断一下，如果已经告警过了则不会再重复打电话提醒。
2. 再比如重复插入，可以通过设置数据库中 unique_index。

真正应用到实际中还要看具体的业务细节。
```

3. **如何保证消息的有序性？全局有序 和 局部有序**

```markdown
保证全局有序：
拿 kafka 举例，只能有一个生产者往 topic 发送消息，并且一个 topic 内部只能有一个队列。消费者也必须是单线程消费。这样消息就是全局有序的。

保证部分有序：
绝大部分的有序需求是部分有序，部分有序我们就可以将 topic 内部划分成我们需要的队列数，把消息通过特定的策略发往固定的队列中(同类的消息发往指定的队列)，然后每个队列对应一个单线程处理的消费者。这样就完成部分有序的需求，又可以通过队列数量的并发来提高消息处理的效率。

如果为了保证消费性能，如果是多个消费者呢？
首先保证队列的数据是有顺序的，另外数据消费的先后数据可以带上一个时间戳，消费者每次去判断是否此次应该先消费，都去比较一下其它消费者和自己手里的这条数据时间戳是不是最小的。是的话就执行起来。那就要保证一种数据只能在一个消费者身上消费了。
```

### 15. 什么是分布式事务？

```markdown
概念：分布式事务用于在分布式系统中保证不同节点之间的数据一致性。

场景：你下单流程可能涉及到10多个环节，你下单付钱都成功了，但是你优惠券扣减失败了，积分新增失败了，前者公司会被薅羊毛，后者用户会不开心。这些功能都在不同的服务上，那么如何保证大家都成功了呢？通过分布式事务来解决。
```

### 16. 分布式事务分为几种？

```
1. 2pc（两段式提交）
2. 2pc（三段式提交）
3. TCC（try、confirm、cancel）
4. 最大努力通知
5. XA
6. 本地消息表
7. 半消息/最终一致性
```

### 17. 说说看什么是两段式提交？

```markdown
通过消息中间件协调了多个系统。参与者将操作成败通知协调者，再由协调者根据所有参与者的反馈情报决定各参与者是否要提交操作，还是中止操作。所谓的二阶段，分别是 投票阶段（准备阶段）、提交阶段。

1. 投票阶段：
	a. 协调者给参与者发送 prepare 消息
	b. 参与者要么直接返回失败，要么就在本地执行事务，写本地的 redo 和 undo 日志，但是不提交。
	c. 参与者在响应给协调节点，表示准备好。
2. 提交阶段：
	a. 协调者收到了所有节点的准备好的响应，向所有节点发送 commit 消息
	b. 参与者正式完成操作，释放在事务期间占用的资源
	c. 向协调节点发送 完成 消息
	d. 协调节点收到所有参与节点的 完成消息后，完成事务。如果有一个或多个事务未成功执行，或者未在约定时间内返回结果，则协调者会向所有参与者发起 rollback 消息。
	e. 参与者反馈回滚结果
	f. 不管结果如何，第二阶段都会结束当前事务。


缺点：
1. 同步阻塞问题
执行过程中，参与者占用了公共资源时，这是恰好有第三方节点访问公共资源，就会不得不处于阻塞成状态。从投票阶段到提交阶段完成的这段时间，资源是被锁住的。
2. 单点故障
一旦协调者发生故障，参与者就会一直阻塞下去。比如说协调者在发出 commit 消息之前就宕机了。。。
3. 数据不一致的问题
比如只有一部分参与者收到了 commit 消息，其它未收到 commit 请求的机器就无法执行事务提交了。此时分布式系统就会出现数据不一致的问题。
```

### 18. 三阶段提交

```markdown
三阶段提交把投票阶段分成两部分，这样就变成了 CanCommit、PreCommit、DoCommit 单个阶段了。加上了 CanCommit 可以在预执行之前，保证所有的参与者都具备可执行的条件，从而减少资源浪费。
```



