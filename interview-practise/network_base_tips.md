## 计算机网络基础

[直接看大神的github](https://github.com/justStarNew/Backend-Interview-Guide/blob/master/doc/%E4%B8%80%E6%96%87%E5%B8%AE%E4%BD%A0%E7%90%86%E6%B8%85%E9%9D%A2%E8%AF%95%E7%9F%A5%E8%AF%86%E7%82%B9.md)

### 1. ★★★ 各层协议的作用，以及 TCP/IP 协议的特点

结合 OSI 七层协议(太多太复杂) 和 TCP/IP(太少) 四层协议的优点，说一下五层协议的体系结构，自上而下介绍：

**1. application layer(应用层)**：

应用层的 **任务** 是 **通过应用进程间的交互来完成特定网络应用**。应用层协议的 **定义** 就是应用进程间通信和交互的规则。这里的 **进程** 指的就是主机中正在运行的程序。应用层协议有：**HTTP、FTP、SMTP** 等等。应用层交互的数据单元成为 **报文(message)。**

 **2. transport layer(运输层)**：

传输层的 **任务** 是负责向 **两个主机中进程之间的通信** 提供 **通用的数据传输** 服务。应用进程利用该服务传送应用层报文。运输层有 **复用** 和 **分用** 的功能，**复用** 就是多个应用层进程可以同时使用下面运输层的服务。**分用** 就是运输层把收到的信息分别交付上面应用层中的相应进程。运输层主要使用以下两种协议：

+ TCP(transport control protocol)

提供 **面向连接**的、**可靠**的数据传输服务，数据传输单位是 **报文段(segment)**。

+ UDP(User datagram protocol)

提供 **无连接**的、**尽最大努力**的数据传输服务，数据的传输单位是 **用户数据报**。

**3. network layer(网络层)**:

网络层的 **任务** 是负责 **为分组交换网上的不同主机提供通信服务**。发送数据时，网络层会把运输层产生的报文段或者用户数据报封装成 **分组** 或 **包(packet)** 进行传送。网络层使用的是 **IP 协议**，因此分组也叫做 **IP 数据报**。

网络层的 **另一个任务** 是 **选择合适的路由，使源主机从传输层下来的分组可以通过网络中的路由器找到目的主机。**

**4. data link layer(数据链路层)**:

两台主机之间的数据传输，总是在一段一段的链路上传送的。数据链路层将网络层下来的数据报组装成 **帧(framing)**，在两个相邻节点间的链路上传送 帧(frame)。每一帧都包含数据和必要的控制信息(同步信息、地址信息、差错控制等)。

**5. physical layer(物理层)**：

在物理层上所传数据的单位是 bit，物理层要考虑用多大的电压来表示 1 和 0。要确认连接电缆的插头应当有多少根引脚以及各条引脚之间应该如何连接。

通过应用进程间的交互来完成特定网络应用。

#### 1.1 TCP/IP 协议的特点

[知乎 TCP/IP协议到底在讲什么](https://www.zhihu.com/question/51074319) 

TCP/IP 是指能够在多个不同网络间实现信息传输的协议簇，TCP/IP 协议不仅仅指 TCP、IP 两个协议，它是在网络使用中的最基本的通信协议。TCP/IP 传输协议对互联网中各部分进行通信的标准和方法都进行了规定。并且，TCP/IP 传输协议是保证网络数据信息及时、完整传输的两个重要协议。严格来说是一个四层模型：应用层、传输层、网络层、网络接口层。

四层模型的 **特点**：(其实书上说四层模型的特点就是简单）

+ 某些程序可以直接使用 IP 层，或者直接使用下面的网络接口层。
+ TCP/IP 协议 可以为各式各样的应用提供服务，同时，TCP/IP 协议也允许 IP 协议在各式各样的网络构成的互联网上运行。IP 协议在因特网中起到了核心作用。

---------------------

### 2. ★★★ 理解三次握手以及四次挥手具体过程，三次握手的原因、四次挥手原因、TIME_WAIT 的作用。

+ **TCP**
  
  + TCP **建立连接**，**三次握手**
    
    + 首先，双方都处于监听的状态，等待客户的连接请求
    + client 向 server 发送一个 SNY 报文段（SYN=1, client_isn - 随机选择的初始序号）
    + server 收到报文段后，从中提取 TCP SYN 报文段，为该 TCP 连接分配 TCP 缓存和变量，然后向 client 发送允许连接的 SYNACK 报文段(SYN=1, client_isn+1， server_isn)
    + client 收到 SYNACK 报文段以后，客户端也要为该连接分配缓存和变量。这个报文段对服务器的 SYNACK 报文段进行了确认(server_isn+1)，又由于连接已经建立，所以 SYN=0，然后发送携带应用层的数据的报文段给 server。并且在之后的每个报文中，SYN 都会被置为 0。
    
    *其中：第二次握手 SYNACK 报文段的意思就是，我收到了你发起建立连接的 SYN 分组，该分组带初始序号 client_isn，我同意建立该连接(client_isn+1)，我自己的初始序号是 server_isn。*
  
  + **三次握手的**原因
    
    + 第三次握手是为了防止失效的数据包到达服务器，让服务器错误地打开连接。
  
  + 客户端的网络请求，如果在网络中发生了滞留，假设服务器要很长时间才能收到这个请求连接的数据包。客户端会等待一个超时重传的时间。重新发送请求连接的数据包。这个时候，服务器那边终于收到了这个请求连接的数据包了，然后朝客户端这里发了一个同意建立连接的数据包。这个时候客户端会因为超时而忽略这个数据包。不会进行第三次握手，因此也就不会打开连接。
  
  + TCP **释放连接**，**四次挥手**
    
    + A发送释放报文（FIN=1），等待B确认，此时 A 处于 FIN_WAIT_1 的状态
    + B 收到释放报文以后返回确认，A 收到确认报文时，变为 FIN_WAIT_2 状态 (此时 连接处于半关闭状态，B 可以向 A 发送数据，A 已经不能向 B发送数据了)
    + 当 B 也不需要连接的时候，发送释放报文 (FIN=1)
    + A 收到释放报文以后返回确认，进入 TIME_WAIT 状态，假定 ACK 丢失，TIME_WAIT 状态使 B 重传最后的确认报文，这个时间可能是 30s，1min，2min。
    + 经过等待以后，连接就会正式关闭，客户端所有字段，包括端口段，都将被释放。
  
  + **四次挥手**的原因
  
  + 1. 由于A发送了关闭连接的请求以后，B发送确认数据包，此时连接就处于半关闭的状态了。这样做是为了让B继续传送他未传完的文件部分。传送完毕以后，B端会发送FIN连接来释放报文。
  
  + **TIME_WAIT**的作用
    
    + 确保最后的一个确认报文能够到达，如果说B没有收到A的确认报文，就会重新发送释放请求报文，所以A要等待一段时间才会完全关闭。
    + 为了让本次连接内的所有报文在网络中消失，使得下一个连接中不会出现旧的请求连接报文。

---------------------

### 3. ★★★ 可靠传输原理，并设计可靠 UDP 协议。

虽然某些实时应用需要使用 没有拥塞控制 的 UDP，但当很多源主机同时都向网络发送高速率的实时视频流时，网络就有可能发生拥塞，结果就是大家都无法正常接收了。不使用拥塞控制的 UDP 可能会导致 严重的 网络拥塞。

可以尝试 **前向纠错** 或 **确认和重传已丢失的报文** 来提高一些可靠性措施。

---------------------

### 4. ★★★ UDP 与 TCP 比较，分析上层协议应该使用 UDP 还是 TCP。

+ **TCP特点**：
  
  ```markdown
    可靠数据传输原理：数据可以通过一条可靠的信道进行传输，借助于可靠信道，传输数据比特就不会收到损坏或者丢失，而且所有数据都是按照其发送顺序进行交付。这恰好就是 TCP 向调用它的因特网应用所提供的服务模型。实现这种服务抽象是 可靠数据传输协议。TCP 是在不可靠的 端到端网络层 之上实现的 可靠数据传输协议,因为底层信道太过于复杂，所以我们始终认为底层是不可靠信道(比特位置可能会出现调换，0变成1，1变成0，比特位丢失等等)。
  ```
  
  + **面向连接**，TCP 连接是一条逻辑连接，共同状态仅仅保留在两个通信端系统的 TCP 程序中。中间的路由器对 TCP 连接完全视而不见，它们看到的是数据报，而不是连接。每条连接都只能是 **点对点** 的。
  + **提供可靠交付**，确保一个进程从其接收缓存中读出的数据流是无损坏、无间隙、非冗余、按序的数据流。
  + **流量控制**，一条 TCP 连接的每一侧主机都为该连接设置了接收缓存，当该 TCP 接收到正确、按序的字节以后，就会将该数据放入接收缓存。相关联的应用进程则从缓存中读取数据。所以如果接收方太慢，发送方太快，就会导致 **接收缓存溢出**。因此流量控制是一个 **速度匹配服务**，即发送方的发送速率与接收方的接收速率相匹配。
    
    (主要方式是接收方返回的 ACK 中会包含自己的接收窗口的大小，利用这个大小来控制发送方的数据发送)
    + **死锁问题**
      
      ```markdown
      指方发送方收到接收方的一个窗口为 0 的应答，于是发送方停止发送数据，等待接收方的下一个应答窗口。但是下一个应答在传输过程中丢失了，发送方就会一直等待，接收方以为发送方收到了，也会继续等待。
      ```
    
    + **死锁问题解决方案**
      
      ```markdown
      TCP 使用了持续计时器，每当发送者收到一个零窗口的应答后就启动该计时器。时间一到就主动发送报文询问接收者的窗口大小。若接收者仍返回零窗口，则重置该计时器继续等待。若窗口不为0，则表示应答报文丢失了，此时重置发送窗口继续发送。
      ```
  + **拥塞控制**，在 TCP 协议中，分组丢失一般被当作网络变得拥塞时由于路由器缓存溢出引起的。因此分组重传时作为网络拥塞的征兆来对待的。一旦发生拥塞，分组所经历的时延会变大，分组丢失的可能性变大，需要重传的分组会变多，形成恶性循环。解决方法有：
    + **慢开始算法**
      
      ```markdown
      发送方维持一个叫做拥塞窗口的状态变量。拥塞窗口的大小取决于网络的拥塞程度，并且动态地在变化。发送发让自己的发送窗口等于拥塞窗口，另外考虑到接收方的接收能力，发送窗口可能小于拥塞窗口。慢开始算法的思路就是，不要一开始发送大量的数据，而是先探测一下网络的拥塞程度，也就是说由小到大逐渐增加拥塞窗口的大小。
      ```
    + **拥塞避免算法**
      
      ```markdown
      拥塞避免算法让拥塞窗口缓慢增长，即每经过一个往返时间 RTT 就把发送方的拥塞窗口 cwnd+1，让拥塞窗口按照线性规律缓慢增长。只要发送方判断网络出现拥塞(比如没有按时收到确认)，让就会把发送窗口设置为之前的一半，拥塞窗口cnwd=1。
      ```
    + **快重传算法 && 快恢复算法**
      
      ```markdown
      快重传要求接收方在收到一个失序的报文段后就立即发出重复确认，而不是等到自己发送数据时捎带确认。
      ```

+ **UDP特点（一样提供复用、分用、差错检测的基础功能）**
  
  1. **在发送数据前不建立连接**，减少了开销和发送数据的时延
  
  2. **尽最大努力交付**，主机不需要维持复杂的连接状态
  
  3. **面向报文**，对于应用层下来的报文，添加首部以后就发送给 IP 层，不会对数据报进行分片，保持数据报的完整性。因此数据报的长度靠应用层来控制，太长的话，IP 层就要负责分片，太短的话，IP 层添加首部又太长，两者的效率都不高。
  
  4. **没有拥塞控制**，即使网络出现拥塞也不会使源主机的发送速率降低。这对某些实时应用是很重要的：1. 要求源主机以恒定的速率发送数据。2. 允许在网络发生拥塞时丢失一些数据。
  
  5. **UDP 支持一对一、一对多、多对一、多对多的交互通信**。
  
  6. **UDP 的首部开销小**，只有 8 bytes，比 TCP 20 bytes 的首部要短。

---------------------

### 5. ★★★ GET 与 POST 比较：作用、参数、安全性、可缓存。

RFC 规范只是指出 GET 的请求参数最好放在 URL 里面，POST 请求参数最好放在请求体里面，但是在 HTTP 协议层面只是指出 GET 请求的含义是获取数据，POST 请求的含义是提交数据。但是并没有强制的限制。

**浏览器/服务器 层面的限制：**

1. 浏览器会对 URL 的长度有限制，比如 Chrome 的最大长度限制是 190,000 个字符。对于超长参数的请求，使用 GET 显然是不合适的。放请求体里面的参数长度是无限制的，但是服务端可能会有限制。
2. 多数浏览器对于 POST 采用的是两阶段发送数据，先发请求头，再发请求体，即使参数再少。在传输层可能发生两次连接的情况，HTTP 协议本身是不保存状态信息的，一次请求一次响应。对于 TCP 来说，连接越少越好，尽量在一次连接中完成数据传输。
3. GET 请求能被 cache, 会被保存在浏览器的浏览历史，POST 则不会进行缓存。

---------------------

### 6. ★★★ HTTP 存在的安全性问题，以及 HTTPs 的加密、认证和完整性作用。

由于 HTTP 采用的是 1. 明文传输 2. 传输过程中不会验证通信双方的身份 3. 接收方和发送方也不会验证报文的完整性。因此进行 HTTP 信息交换的双方可能会遭到伪装，截获，篡改等问题。

**HTTPS = HTTP + Secure(TLS/SSL)**     端口：443

HTTPS 和 HTTP 的区别只是，HTTP 的通信接口部分由 SSL 和 TLS 替代。通常情况下 HTTP 会先直接和 TCP 通信，使用了 SSL 之后，则会变成 HTTP 和 SSL 通信，SSL 和 TCP 通信。TSL 采用了 对称、非对称加密，身份认证等许多密码学技术。

+ 加密（数据加密）- 对称、非堆成加密
+ 数据一致性（保证发送端发出的是什么，接收端就收到什么）- 数据摘要算法
+ 身份认证（确认对方真实身份，防止中间人攻击并建立用户信任）- CA  证书认证机构

----------

### 7. ★★★ Cookie 作用、安全性问题、和 Session 的比较。

[what is cookie?](http://www.whatarecookies.com/)

```markdown
**Cookie 是一种将信息从网站上的 一个会话传送到另一个会话 或 在相关网站上的会话之间传送信息 的便捷方法**。减轻服务器数据存储的负担。比如用户第一次访问某站点的时候，cookie 可以选择存储用户信息，如 username, password。这样当用户再次登录的时候，不需要重新输入信息。Cookie 通常以 **匿名方式** 标识特定的访问者或特定的计算机。
```

[what is session?](https://stackoverflow.com/questions/3804209/what-are-sessions-how-do-they-work)

```markdown
Session 是指 访问者首次到达网站页面到停止使用该网站之间的时间。为了跟踪会话，会将 web session id 存储在 访问者 的 浏览器 中。服务器日志通常会包含访问者的 session id 和 cookie id。web session id 对于特定的访问是唯一的，但是 cookie 对于特定的访问者是唯一的。
```

非要说两者最大的区别，大概就是，一个用户信息存储在浏览器，不太安全，可能会被第三方网站盗读，或者修改。但是 session id 的方式，session 是存储在 服务器端的，存储在服务器端可能比较安全。

------------

### ★★★ 长连接与短连接原理以及使用场景，流水线。

**长连接**

+ 定义：指在一个 TCP 连接上可以连续发送多个数据包，在 TCP 连接保持期间，如果没有数据包发送，需要双方发检测包维持此连接。
+ 场景：在需要频繁请求资源的场景来说，长连接可以省去较多的 TCP 建立连接和关闭连接的操作。但是长连接的维持时间需要控制，server 可以关闭一些长时间没有读写事件发生的连接、限制 client 的最大长连接数等等。
+ 实例：数据库连接

**短连接**

+ 定义：指通信双方交互时，就建立一个 TCP 连接，数据发送完成后，就断开 TCP 连接。

+ 场景：并发量大，每个用户无需频繁操作的场景下，使用长连接会占用过多服务器资源，使用短连接会更好。

+ 实例：web 服务

-------------------------

### ★★☆ 以太网的特点，以及帧结构。

### ★★☆ 集线器、交换机、路由器的作用，以及所属的网络层。

### ★★☆ IP 数据数据报常见字段的作用。

### ★☆☆ ARP 协议的作用，以及维护 ARP 缓存的过程。

### ★★☆ ICMP 报文种类以及作用；和 IP 数据报的关系；Ping 和 Traceroute 的具体原理。

### ★★☆ TCP 拥塞控制的作用，理解具体原理。

### ★★☆ DNS 的端口号；TCP 还是 UDP；作为缓存、负载均衡。

### ★★☆ HTTP 状态码。

### ★★☆ 缓存 的Cache-Control 字段，特别是 Expires 和 max-age 的区别。ETag 验证原理。

### ★★☆ HTTP/1.x 的缺陷，以及 HTTP/2 的特点。

### ★★★ HTTP/1.1 的特性。

### ★★☆ HTTP 与 FTP 的比较。

### ★★☆ 五种 IO 模型的特点以及比较。

### ★★★ select、poll、epoll 的原理、比较、以及使用场景；epoll 的水平触发与边缘触发。
